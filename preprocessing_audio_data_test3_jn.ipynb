{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBb8Wrc4nGjO",
        "outputId": "23b793ba-7f87-422f-c272-73b638b467b8"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import Wav2Vec2ForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "from datasets import Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yGVYd1snGjP"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class Sample:\n",
        "            pass\n",
        "        sample = Sample()\n",
        "        sample.input_ids = self.features[idx]\n",
        "        sample.labels = self.labels[idx]\n",
        "        return sample\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AzVsm3hnGjQ",
        "outputId": "dae594f7-4d61-4583-c795-f0b37ac841d4"
      },
      "outputs": [],
      "source": [
        "# Assuming you have a DataFrame with columns \"filename\" and \"emotion\"\n",
        "# data = pd.read_csv(\"C:/MyDocs/DTU/MSc/Thesis/Data/MELD/MELD_preprocess_test/pre_process_test.csv\")\n",
        "# data = pd.read_csv(\"C:/Users/DANIEL/Desktop/thesis/low-resource-emotion-recognition/MELD_preprocess_test/pre_process_test.csv\")\n",
        "data = pd.read_csv('/train_labels_corrected.csv')\n",
        "\n",
        "# directory = \"C:/MyDocs/DTU/MSc/Thesis/Data/MELD/MELD_preprocess_test/MELD_preprocess_test_data\"\n",
        "zip_path = '/train_audio-002.zip'\n",
        "extract_to = '/data'\n",
        "# os.makedirs(extract_to, exist_ok=True)\n",
        "# directory = '/content/drive/My Drive/Thesis_Data/MELD/Run3/data/train_audio.zip'\n",
        "\n",
        "if not os.listdir(extract_to):\n",
        "    # If the directory is empty, extract the files\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"Files extracted successfully!\")\n",
        "else:\n",
        "    print(\"Directory is not empty. Extraction skipped to avoid overwriting.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZCFKReoU-iN",
        "outputId": "1f2d692a-7e77-4573-ad85-26df209891fa"
      },
      "outputs": [],
      "source": [
        "files = []\n",
        "\n",
        "directory = os.path.join(extract_to, \"train_audio\")\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "for file in os.listdir(directory):\n",
        "    if file.endswith('.wav'):\n",
        "        files.append(file)\n",
        "\n",
        "# Add filenames to a new column in the DataFrame\n",
        "data['filename'] = files\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "raw_labels = data['Emotion'].values\n",
        "labels = label_encoder.fit_transform(raw_labels)\n",
        "\n",
        "# Show the label-encoding pairs:\n",
        "print(label_encoder.classes_)\n",
        "print(\"[0,         1,       2,       3,         4,         5,   6]\")\n",
        "\n",
        "print(labels)\n",
        "\n",
        "max_length = 16000 * 9  # 9 seconds\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "\n",
        "    # Load audio file\n",
        "    file_to_load = row['filename']\n",
        "    file_to_load_path = os.path.join(directory, file_to_load)\n",
        "    # print()\n",
        "    # print(index)\n",
        "    # print(file_to_load)\n",
        "    # print()\n",
        "\n",
        "    audio, sr = librosa.load(file_to_load_path, sr=16000)\n",
        "\n",
        "    if len(audio) > max_length:\n",
        "        audio = audio[:max_length]\n",
        "    else:\n",
        "        padding = max_length - len(audio)\n",
        "        offset = padding // 2\n",
        "        audio = np.pad(audio, (offset, padding - offset), 'constant')\n",
        "\n",
        "\n",
        "    features.append(audio)\n",
        "\n",
        "    # Encode label\n",
        "    # labels.append(label_encoder.transform([row['Emotion']]))\n",
        "\n",
        "# Convert to arrays\n",
        "features = np.array(features)\n",
        "labels = np.array(labels).flatten()\n",
        "\n",
        "\n",
        "# Now, `features` and `labels` can be used for training your model\n",
        "# Optionally, save them to disk\n",
        "# np.save('features.npy', features)\n",
        "# np.save('labels.npy', labels)\n",
        "\n",
        "print(features.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "# Convert features to a float tensor and transpose the last two dimensions\n",
        "features_tensor = torch.tensor(features).float()\n",
        "labels_tensor = torch.tensor(labels).long()  # Use .long() for integer labels, .float() for one-hot\n",
        "\n",
        "# Choose train indices and validation indices\n",
        "train_indices = np.random.choice(len(features), int(0.8 * len(features)), replace=False)\n",
        "val_indices = np.array([i for i in range(len(features)) if i not in train_indices])\n",
        "\n",
        "\n",
        "# Convert the TensorDatasets to Datasets\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'input_values': features_tensor[train_indices],\n",
        "    'labels': labels_tensor[train_indices]\n",
        "})\n",
        "val_dataset = Dataset.from_dict({\n",
        "    'input_values': features_tensor[val_indices],\n",
        "    'labels': labels_tensor[val_indices]\n",
        "})\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Load a pre-trained model for pretrained\n",
        "model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\", num_labels=7)\n",
        "\n",
        "# Define training arguments\n",
        "# training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
        "\n",
        "# Initialize the trainer\n",
        "metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ODLVXoMUnGjQ",
        "outputId": "29e08740-248e-418e-bd37-dbac466922d8"
      },
      "outputs": [],
      "source": [
        "# Prepare the trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory\n",
        "    num_train_epochs=20,             # Number of training epochs\n",
        "    per_device_train_batch_size=4,   # Batch size for training\n",
        "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
        "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # Strength of weight decay\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=10,\n",
        "    save_strategy='steps',               # Saving model checkpoint strategy\n",
        "    save_steps=500,                      # Save checkpoint every 500 steps\n",
        "    save_total_limit=3\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'emotion_recognition_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqe_p92KnGjR"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/My Drive/Thesis_Data/MELD/Run2/model/emotion_recognition_model.pth'\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
