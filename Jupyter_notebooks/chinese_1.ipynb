{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfW-hFwijFae",
        "outputId": "9976443b-e3ab-440b-84ab-a4073dd5243a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras_vggface is already installed with version 0.6\n",
            "keras_applications is already installed with version 1.0.8\n",
            "batch_face is already installed with version 1.4.0\n",
            "speechbrain is already installed with version 1.0.0\n",
            "Google Drive is already mounted.\n",
            "Modules directory already exists. No need to extract the ZIP file.\n",
            "Multimodal modules directory already exists. No need to extract the ZIP file.\n",
            "Video data folder already exists. No need to extract the ZIP file.\n",
            "Audio data folder already exists. No need to extract the ZIP file.\n",
            "-----------------------------------------------\n",
            "Processing file 1/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0001_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0001_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0001_0004.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  25.0\n",
            "Video duration: 3.88 s\n",
            "Frame width: 1920\n",
            "Frame height: 804\n",
            "-----------------------------------------------\n",
            "Processing file 2/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0001_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0001_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0001_0010.mp4\n",
            "Number total of frames:  82\n",
            "FPS:  25.0\n",
            "Video duration: 3.28 s\n",
            "Frame width: 1920\n",
            "Frame height: 804\n",
            "-----------------------------------------------\n",
            "Processing file 3/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0001_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0001_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0001_0013.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  25.0\n",
            "Video duration: 2.16 s\n",
            "Frame width: 1920\n",
            "Frame height: 804\n",
            "-----------------------------------------------\n",
            "Processing file 4/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0001_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0001_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0001_0015.mp4\n",
            "Number total of frames:  103\n",
            "FPS:  25.0\n",
            "Video duration: 4.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 804\n",
            "-----------------------------------------------\n",
            "Processing file 5/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0001_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0001_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0001_0020.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  25.0\n",
            "Video duration: 2.48 s\n",
            "Frame width: 1920\n",
            "Frame height: 804\n",
            "-----------------------------------------------\n",
            "Processing file 6/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0001_0035.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0001_0035.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0001_0035.mp4\n",
            "Number total of frames:  46\n",
            "FPS:  25.0\n",
            "Video duration: 1.84 s\n",
            "Frame width: 1920\n",
            "Frame height: 804\n",
            "-----------------------------------------------\n",
            "Processing file 7/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0002.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  25.0\n",
            "Video duration: 2.96 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 8/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0005.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  25.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 9/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0012.mp4\n",
            "Number total of frames:  106\n",
            "FPS:  25.0\n",
            "Video duration: 4.24 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 10/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0013.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  25.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 11/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0018.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  25.0\n",
            "Video duration: 2.96 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 12/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0019.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  25.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 13/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0024.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0024.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0024.mp4\n",
            "Number total of frames:  112\n",
            "FPS:  25.0\n",
            "Video duration: 4.48 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 14/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0027.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0027.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0027.mp4\n",
            "Number total of frames:  159\n",
            "FPS:  25.0\n",
            "Video duration: 6.36 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 15/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0031.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0031.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0031.mp4\n",
            "Number total of frames:  112\n",
            "FPS:  25.0\n",
            "Video duration: 4.48 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 16/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0002_0036.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0002_0036.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0002_0036.mp4\n",
            "Number total of frames:  129\n",
            "FPS:  25.0\n",
            "Video duration: 5.16 s\n",
            "Frame width: 1920\n",
            "Frame height: 760\n",
            "-----------------------------------------------\n",
            "Processing file 17/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0003_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0003_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0003_0003.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  24.0\n",
            "Video duration: 3.46 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 18/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0005_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0005_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0005_0004.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  25.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 1920\n",
            "Frame height: 1072\n",
            "-----------------------------------------------\n",
            "Processing file 19/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0005_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0005_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0005_0007.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  25.0\n",
            "Video duration: 3.32 s\n",
            "Frame width: 1920\n",
            "Frame height: 1072\n",
            "-----------------------------------------------\n",
            "Processing file 20/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0005_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0005_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0005_0009.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  25.0\n",
            "Video duration: 2.72 s\n",
            "Frame width: 1920\n",
            "Frame height: 1072\n",
            "-----------------------------------------------\n",
            "Processing file 21/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0006_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0006_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0006_0006.mp4\n",
            "Number total of frames:  45\n",
            "FPS:  24.0\n",
            "Video duration: 1.88 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 22/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0006_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0006_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0006_0011.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  24.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 23/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0006_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0006_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0006_0022.mp4\n",
            "Number total of frames:  73\n",
            "FPS:  24.0\n",
            "Video duration: 3.04 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 24/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0007_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0007_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0007_0006.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  24.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 25/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0008_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0008_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0008_0004.mp4\n",
            "Number total of frames:  33\n",
            "FPS:  24.0\n",
            "Video duration: 1.38 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "Checkpoint 25 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 26/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0008_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0008_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0008_0005.mp4\n",
            "Number total of frames:  82\n",
            "FPS:  24.0\n",
            "Video duration: 3.42 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 27/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0008_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0008_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0008_0007.mp4\n",
            "Number total of frames:  29\n",
            "FPS:  24.0\n",
            "Video duration: 1.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 28/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0008_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0008_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0008_0010.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  24.0\n",
            "Video duration: 4.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 29/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0001.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  25.0\n",
            "Video duration: 2.48 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 30/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0002.mp4\n",
            "Number total of frames:  39\n",
            "FPS:  25.0\n",
            "Video duration: 1.56 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 31/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0010.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  25.0\n",
            "Video duration: 2.72 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 32/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0012.mp4\n",
            "Number total of frames:  103\n",
            "FPS:  25.0\n",
            "Video duration: 4.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 33/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0013.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  25.0\n",
            "Video duration: 3.52 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 34/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0016.mp4\n",
            "Number total of frames:  52\n",
            "FPS:  25.0\n",
            "Video duration: 2.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 35/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0017.mp4\n",
            "Number total of frames:  145\n",
            "FPS:  25.0\n",
            "Video duration: 5.8 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 36/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0018.mp4\n",
            "Number total of frames:  156\n",
            "FPS:  25.0\n",
            "Video duration: 6.24 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 37/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0029.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0029.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0029.mp4\n",
            "Number total of frames:  61\n",
            "FPS:  25.0\n",
            "Video duration: 2.44 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 38/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0035.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0035.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0035.mp4\n",
            "Number total of frames:  119\n",
            "FPS:  25.0\n",
            "Video duration: 4.76 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 39/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0009_0041.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0009_0041.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0009_0041.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  25.0\n",
            "Video duration: 2.64 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 40/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0003.mp4\n",
            "Number total of frames:  133\n",
            "FPS:  24.0\n",
            "Video duration: 5.54 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 41/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0006.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  24.0\n",
            "Video duration: 4.04 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 42/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0008.mp4\n",
            "Number total of frames:  180\n",
            "FPS:  24.0\n",
            "Video duration: 7.5 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 43/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0010.mp4\n",
            "Number total of frames:  119\n",
            "FPS:  24.0\n",
            "Video duration: 4.96 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 44/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0011.mp4\n",
            "Number total of frames:  119\n",
            "FPS:  24.0\n",
            "Video duration: 4.96 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 45/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0013.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  24.0\n",
            "Video duration: 3.33 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 46/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0025.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0025.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0025.mp4\n",
            "Number total of frames:  55\n",
            "FPS:  24.0\n",
            "Video duration: 2.29 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 47/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0026.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0026.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0026.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  24.0\n",
            "Video duration: 2.62 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 48/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0029.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0029.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0029.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  24.0\n",
            "Video duration: 3.08 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 49/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0010_0033.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0010_0033.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0010_0033.mp4\n",
            "Number total of frames:  102\n",
            "FPS:  24.0\n",
            "Video duration: 4.25 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 50/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0011_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0011_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0011_0003.mp4\n",
            "Number total of frames:  113\n",
            "FPS:  25.0\n",
            "Video duration: 4.52 s\n",
            "Frame width: 960\n",
            "Frame height: 540\n",
            "Checkpoint 50 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 51/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0011_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0011_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0011_0005.mp4\n",
            "Number total of frames:  48\n",
            "FPS:  25.0\n",
            "Video duration: 1.92 s\n",
            "Frame width: 960\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 52/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0011_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0011_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0011_0008.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  25.0\n",
            "Video duration: 2.28 s\n",
            "Frame width: 960\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 53/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0011_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0011_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0011_0014.mp4\n",
            "Number total of frames:  50\n",
            "FPS:  25.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 960\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 54/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0011_0029.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0011_0029.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0011_0029.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  25.0\n",
            "Video duration: 3.48 s\n",
            "Frame width: 960\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 55/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0011_0033.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0011_0033.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0011_0033.mp4\n",
            "Number total of frames:  82\n",
            "FPS:  25.0\n",
            "Video duration: 3.28 s\n",
            "Frame width: 960\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 56/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0001.mp4\n",
            "Number total of frames:  38\n",
            "FPS:  25.0\n",
            "Video duration: 1.52 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 57/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0002.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  25.0\n",
            "Video duration: 3.48 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 58/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0003.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  25.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 59/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0015.mp4\n",
            "Number total of frames:  119\n",
            "FPS:  25.0\n",
            "Video duration: 4.76 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 60/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0020.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  25.0\n",
            "Video duration: 3.76 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 61/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0025.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0025.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0025.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  25.0\n",
            "Video duration: 3.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 62/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0028.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0028.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0028.mp4\n",
            "Number total of frames:  107\n",
            "FPS:  25.0\n",
            "Video duration: 4.28 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 63/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0031.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0031.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0031.mp4\n",
            "Number total of frames:  112\n",
            "FPS:  25.0\n",
            "Video duration: 4.48 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 64/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0038.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0038.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0038.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  25.0\n",
            "Video duration: 3.88 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 65/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0040.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0040.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0040.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  25.0\n",
            "Video duration: 3.24 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 66/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0012_0046.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0012_0046.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0012_0046.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  25.0\n",
            "Video duration: 3.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 67/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0013_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0013_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0013_0002.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  25.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 1024\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 68/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0013_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0013_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0013_0003.mp4\n",
            "Number total of frames:  50\n",
            "FPS:  25.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 1024\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 69/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0013_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0013_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0013_0004.mp4\n",
            "Number total of frames:  104\n",
            "FPS:  25.0\n",
            "Video duration: 4.16 s\n",
            "Frame width: 1024\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 70/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0013_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0013_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0013_0008.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  25.0\n",
            "Video duration: 3.44 s\n",
            "Frame width: 1024\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 71/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0013_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0013_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0013_0015.mp4\n",
            "Number total of frames:  140\n",
            "FPS:  25.0\n",
            "Video duration: 5.6 s\n",
            "Frame width: 1024\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 72/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0013_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0013_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0013_0016.mp4\n",
            "Number total of frames:  51\n",
            "FPS:  25.0\n",
            "Video duration: 2.04 s\n",
            "Frame width: 1024\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 73/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0013_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0013_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0013_0034.mp4\n",
            "Number total of frames:  112\n",
            "FPS:  25.0\n",
            "Video duration: 4.48 s\n",
            "Frame width: 1024\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 74/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0001.mp4\n",
            "Number total of frames:  133\n",
            "FPS:  24.0\n",
            "Video duration: 5.54 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 75/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0004.mp4\n",
            "Number total of frames:  110\n",
            "FPS:  24.0\n",
            "Video duration: 4.58 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "Checkpoint 75 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 76/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0005.mp4\n",
            "Number total of frames:  109\n",
            "FPS:  24.0\n",
            "Video duration: 4.54 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 77/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0009.mp4\n",
            "Number total of frames:  163\n",
            "FPS:  24.0\n",
            "Video duration: 6.79 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 78/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0012.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  24.0\n",
            "Video duration: 3.58 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 79/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0014.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  24.0\n",
            "Video duration: 2.71 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 80/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0016.mp4\n",
            "Number total of frames:  100\n",
            "FPS:  24.0\n",
            "Video duration: 4.17 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 81/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0020.mp4\n",
            "Number total of frames:  125\n",
            "FPS:  24.0\n",
            "Video duration: 5.21 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 82/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0014_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0014_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0014_0022.mp4\n",
            "Number total of frames:  176\n",
            "FPS:  24.0\n",
            "Video duration: 7.33 s\n",
            "Frame width: 1920\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 83/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0004.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  25.0\n",
            "Video duration: 2.88 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 84/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0009.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  25.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 85/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0010.mp4\n",
            "Number total of frames:  36\n",
            "FPS:  25.0\n",
            "Video duration: 1.44 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 86/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0016.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  25.0\n",
            "Video duration: 2.16 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 87/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0017.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  25.0\n",
            "Video duration: 2.16 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 88/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0019.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  25.0\n",
            "Video duration: 3.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 89/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0022.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  25.0\n",
            "Video duration: 2.24 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 90/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0023.mp4\n",
            "Number total of frames:  48\n",
            "FPS:  25.0\n",
            "Video duration: 1.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 91/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0024.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0024.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0024.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  25.0\n",
            "Video duration: 2.52 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 92/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0031.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0031.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0031.mp4\n",
            "Number total of frames:  114\n",
            "FPS:  25.0\n",
            "Video duration: 4.56 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 93/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0033.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0033.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0033.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  25.0\n",
            "Video duration: 3.44 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 94/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0037.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0037.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0037.mp4\n",
            "Number total of frames:  182\n",
            "FPS:  25.0\n",
            "Video duration: 7.28 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 95/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0039.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0039.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0039.mp4\n",
            "Number total of frames:  55\n",
            "FPS:  25.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 96/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0015_0040.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0015_0040.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0015_0040.mp4\n",
            "Number total of frames:  152\n",
            "FPS:  25.0\n",
            "Video duration: 6.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 480\n",
            "-----------------------------------------------\n",
            "Processing file 97/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0008.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  25.0\n",
            "Video duration: 3.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 98/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0015.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  25.0\n",
            "Video duration: 2.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 99/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0018.mp4\n",
            "Number total of frames:  137\n",
            "FPS:  25.0\n",
            "Video duration: 5.48 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 100/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0025.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0025.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0025.mp4\n",
            "Number total of frames:  73\n",
            "FPS:  25.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "Checkpoint 100 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 101/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0030.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0030.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0030.mp4\n",
            "Number total of frames:  134\n",
            "FPS:  25.0\n",
            "Video duration: 5.36 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 102/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0039.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0039.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0039.mp4\n",
            "Number total of frames:  225\n",
            "FPS:  25.0\n",
            "Video duration: 9.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 103/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0042.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0042.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0042.mp4\n",
            "Number total of frames:  43\n",
            "FPS:  25.0\n",
            "Video duration: 1.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 104/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0044.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0044.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0044.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  25.0\n",
            "Video duration: 3.76 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 105/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0045.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0045.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0045.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  25.0\n",
            "Video duration: 2.76 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 106/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0016_0046.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0016_0046.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0016_0046.mp4\n",
            "Number total of frames:  144\n",
            "FPS:  25.0\n",
            "Video duration: 5.76 s\n",
            "Frame width: 1280\n",
            "Frame height: 580\n",
            "-----------------------------------------------\n",
            "Processing file 107/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0017_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0017_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0017_0001.mp4\n",
            "Number total of frames:  150\n",
            "FPS:  24.0\n",
            "Video duration: 6.25 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 108/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0017_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0017_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0017_0003.mp4\n",
            "Number total of frames:  55\n",
            "FPS:  24.0\n",
            "Video duration: 2.29 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 109/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0017_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0017_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0017_0004.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  24.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 110/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0017_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0017_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0017_0006.mp4\n",
            "Number total of frames:  259\n",
            "FPS:  24.0\n",
            "Video duration: 10.79 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 111/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0017_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0017_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0017_0007.mp4\n",
            "Number total of frames:  187\n",
            "FPS:  24.0\n",
            "Video duration: 7.79 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 112/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0017_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0017_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0017_0010.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  24.0\n",
            "Video duration: 3.5 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 113/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0017_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0017_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0017_0016.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  24.0\n",
            "Video duration: 3.58 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 114/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0018_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0018_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0018_0003.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  25.0\n",
            "Video duration: 2.36 s\n",
            "Frame width: 1920\n",
            "Frame height: 864\n",
            "-----------------------------------------------\n",
            "Processing file 115/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0018_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0018_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0018_0004.mp4\n",
            "Number total of frames:  52\n",
            "FPS:  25.0\n",
            "Video duration: 2.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 864\n",
            "-----------------------------------------------\n",
            "Processing file 116/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0018_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0018_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0018_0007.mp4\n",
            "Number total of frames:  45\n",
            "FPS:  25.0\n",
            "Video duration: 1.8 s\n",
            "Frame width: 1920\n",
            "Frame height: 864\n",
            "-----------------------------------------------\n",
            "Processing file 117/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0018_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0018_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0018_0010.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  25.0\n",
            "Video duration: 4.04 s\n",
            "Frame width: 1920\n",
            "Frame height: 864\n",
            "-----------------------------------------------\n",
            "Processing file 118/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0019_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0019_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0019_0005.mp4\n",
            "Number total of frames:  51\n",
            "FPS:  24.0\n",
            "Video duration: 2.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 119/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0019_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0019_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0019_0011.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  24.0\n",
            "Video duration: 2.75 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 120/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0019_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0019_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0019_0012.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  24.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 121/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0019_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0019_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0019_0015.mp4\n",
            "Number total of frames:  105\n",
            "FPS:  24.0\n",
            "Video duration: 4.38 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 122/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0020_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0020_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0020_0003.mp4\n",
            "Number total of frames:  132\n",
            "FPS:  24.0\n",
            "Video duration: 5.5 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "-----------------------------------------------\n",
            "Processing file 123/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0020_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0020_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0020_0004.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  24.0\n",
            "Video duration: 3.75 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "-----------------------------------------------\n",
            "Processing file 124/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0021_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0021_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0021_0002.mp4\n",
            "Number total of frames:  162\n",
            "FPS:  24.0\n",
            "Video duration: 6.75 s\n",
            "Frame width: 1280\n",
            "Frame height: 536\n",
            "-----------------------------------------------\n",
            "Processing file 125/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0022_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0022_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0022_0003.mp4\n",
            "Number total of frames:  85\n",
            "FPS:  24.0\n",
            "Video duration: 3.54 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "Checkpoint 125 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 126/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0022_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0022_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0022_0004.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  24.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "-----------------------------------------------\n",
            "Processing file 127/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0022_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0022_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0022_0006.mp4\n",
            "Number total of frames:  139\n",
            "FPS:  24.0\n",
            "Video duration: 5.79 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "-----------------------------------------------\n",
            "Processing file 128/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0022_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0022_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0022_0016.mp4\n",
            "Number total of frames:  107\n",
            "FPS:  24.0\n",
            "Video duration: 4.46 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "-----------------------------------------------\n",
            "Processing file 129/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0022_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0022_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0022_0017.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  24.0\n",
            "Video duration: 3.5 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "-----------------------------------------------\n",
            "Processing file 130/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0013.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  24.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 131/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0017.mp4\n",
            "Number total of frames:  125\n",
            "FPS:  24.0\n",
            "Video duration: 5.21 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 132/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0018.mp4\n",
            "Number total of frames:  115\n",
            "FPS:  24.0\n",
            "Video duration: 4.79 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 133/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0023.mp4\n",
            "Number total of frames:  130\n",
            "FPS:  24.0\n",
            "Video duration: 5.42 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 134/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0045.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0045.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0045.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  24.0\n",
            "Video duration: 3.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 135/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0046.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0046.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0046.mp4\n",
            "Number total of frames:  48\n",
            "FPS:  24.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 136/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0049.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0049.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0049.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  24.0\n",
            "Video duration: 2.71 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 137/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0054.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0054.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0054.mp4\n",
            "Number total of frames:  133\n",
            "FPS:  24.0\n",
            "Video duration: 5.54 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 138/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0061.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0061.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0061.mp4\n",
            "Number total of frames:  126\n",
            "FPS:  24.0\n",
            "Video duration: 5.25 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 139/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0023_0062.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0023_0062.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0023_0062.mp4\n",
            "Number total of frames:  161\n",
            "FPS:  24.0\n",
            "Video duration: 6.71 s\n",
            "Frame width: 1920\n",
            "Frame height: 1078\n",
            "-----------------------------------------------\n",
            "Processing file 140/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0003.mp4\n",
            "Number total of frames:  58\n",
            "FPS:  24.0\n",
            "Video duration: 2.42 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 141/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0008.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  24.0\n",
            "Video duration: 3.21 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 142/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0011.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  24.0\n",
            "Video duration: 3.71 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 143/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0012.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  24.0\n",
            "Video duration: 3.46 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 144/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0016.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  24.0\n",
            "Video duration: 2.71 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 145/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0018.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  24.0\n",
            "Video duration: 2.88 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 146/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0021.mp4\n",
            "Number total of frames:  29\n",
            "FPS:  24.0\n",
            "Video duration: 1.21 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 147/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0023.mp4\n",
            "Number total of frames:  111\n",
            "FPS:  24.0\n",
            "Video duration: 4.62 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 148/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0030.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0030.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0030.mp4\n",
            "Number total of frames:  35\n",
            "FPS:  24.0\n",
            "Video duration: 1.46 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 149/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0032.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0032.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0032.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  24.0\n",
            "Video duration: 3.96 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 150/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0034.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  24.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "Checkpoint 150 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 151/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0038.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0038.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0038.mp4\n",
            "Number total of frames:  47\n",
            "FPS:  24.0\n",
            "Video duration: 1.96 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 152/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0043.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0043.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0043.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  24.0\n",
            "Video duration: 2.33 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 153/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0046.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0046.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0046.mp4\n",
            "Number total of frames:  114\n",
            "FPS:  24.0\n",
            "Video duration: 4.75 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 154/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0047.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0047.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0047.mp4\n",
            "Number total of frames:  108\n",
            "FPS:  24.0\n",
            "Video duration: 4.5 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 155/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0055.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0055.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0055.mp4\n",
            "Number total of frames:  34\n",
            "FPS:  24.0\n",
            "Video duration: 1.42 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 156/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0059.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0059.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0059.mp4\n",
            "Number total of frames:  26\n",
            "FPS:  24.0\n",
            "Video duration: 1.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 157/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0063.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0063.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0063.mp4\n",
            "Number total of frames:  50\n",
            "FPS:  24.0\n",
            "Video duration: 2.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 158/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0066.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0066.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0066.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  24.0\n",
            "Video duration: 3.25 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 159/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0070.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0070.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0070.mp4\n",
            "Number total of frames:  73\n",
            "FPS:  24.0\n",
            "Video duration: 3.04 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 160/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0071.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0071.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0071.mp4\n",
            "Number total of frames:  58\n",
            "FPS:  24.0\n",
            "Video duration: 2.42 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 161/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0073.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0073.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0073.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  24.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 162/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0076.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0076.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0076.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  24.0\n",
            "Video duration: 3.25 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 163/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0078.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0078.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0078.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  24.0\n",
            "Video duration: 2.46 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 164/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0083.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0083.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0083.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  24.0\n",
            "Video duration: 3.83 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 165/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0093.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0093.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0093.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  24.0\n",
            "Video duration: 2.33 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 166/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0095.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0095.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0095.mp4\n",
            "Number total of frames:  50\n",
            "FPS:  24.0\n",
            "Video duration: 2.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 167/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0096.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0096.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0096.mp4\n",
            "Number total of frames:  115\n",
            "FPS:  24.0\n",
            "Video duration: 4.79 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 168/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0097.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0097.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0097.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  24.0\n",
            "Video duration: 3.71 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 169/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0098.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0098.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0098.mp4\n",
            "Number total of frames:  98\n",
            "FPS:  24.0\n",
            "Video duration: 4.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 170/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0104.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0104.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0104.mp4\n",
            "Number total of frames:  98\n",
            "FPS:  24.0\n",
            "Video duration: 4.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 171/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0105.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0105.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0105.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  24.0\n",
            "Video duration: 3.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 172/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0109.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0109.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0109.mp4\n",
            "Number total of frames:  32\n",
            "FPS:  24.0\n",
            "Video duration: 1.33 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 173/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0111.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0111.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0111.mp4\n",
            "Number total of frames:  121\n",
            "FPS:  24.0\n",
            "Video duration: 5.04 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 174/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0024_0114.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0024_0114.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0024_0114.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  24.0\n",
            "Video duration: 4.04 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 175/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0001.mp4\n",
            "Number total of frames:  133\n",
            "FPS:  24.0\n",
            "Video duration: 5.54 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "Checkpoint 175 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 176/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0007.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  24.0\n",
            "Video duration: 3.58 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 177/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0019.mp4\n",
            "Number total of frames:  32\n",
            "FPS:  24.0\n",
            "Video duration: 1.33 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 178/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0022.mp4\n",
            "Number total of frames:  48\n",
            "FPS:  24.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 179/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0025.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0025.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0025.mp4\n",
            "Number total of frames:  67\n",
            "FPS:  24.0\n",
            "Video duration: 2.79 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 180/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0028.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0028.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0028.mp4\n",
            "Number total of frames:  44\n",
            "FPS:  24.0\n",
            "Video duration: 1.83 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 181/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0031.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0031.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0031.mp4\n",
            "Number total of frames:  102\n",
            "FPS:  24.0\n",
            "Video duration: 4.25 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 182/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0039.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0039.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0039.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  24.0\n",
            "Video duration: 3.88 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 183/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0040.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0040.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0040.mp4\n",
            "Number total of frames:  114\n",
            "FPS:  24.0\n",
            "Video duration: 4.75 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 184/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0025_0050.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0025_0050.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0025_0050.mp4\n",
            "Number total of frames:  61\n",
            "FPS:  24.0\n",
            "Video duration: 2.54 s\n",
            "Frame width: 1920\n",
            "Frame height: 800\n",
            "-----------------------------------------------\n",
            "Processing file 185/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0026_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0026_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0026_0001.mp4\n",
            "Number total of frames:  103\n",
            "FPS:  24.0\n",
            "Video duration: 4.29 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 186/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0026_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0026_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0026_0005.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  24.0\n",
            "Video duration: 4.04 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 187/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0026_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0026_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0026_0007.mp4\n",
            "Number total of frames:  246\n",
            "FPS:  24.0\n",
            "Video duration: 10.25 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 188/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0026_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0026_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0026_0016.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  24.0\n",
            "Video duration: 3.83 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 189/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0026_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0026_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0026_0019.mp4\n",
            "Number total of frames:  149\n",
            "FPS:  24.0\n",
            "Video duration: 6.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 190/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0026_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0026_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0026_0021.mp4\n",
            "Number total of frames:  109\n",
            "FPS:  24.0\n",
            "Video duration: 4.54 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 191/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0026_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0026_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0026_0022.mp4\n",
            "Number total of frames:  185\n",
            "FPS:  24.0\n",
            "Video duration: 7.71 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 192/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0026_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0026_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0026_0023.mp4\n",
            "Number total of frames:  100\n",
            "FPS:  24.0\n",
            "Video duration: 4.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 193/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0001.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  24.0\n",
            "Video duration: 3.38 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 194/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0005.mp4\n",
            "Number total of frames:  100\n",
            "FPS:  24.0\n",
            "Video duration: 4.17 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 195/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0009.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  24.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 196/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0013.mp4\n",
            "Number total of frames:  102\n",
            "FPS:  24.0\n",
            "Video duration: 4.25 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 197/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0016.mp4\n",
            "Number total of frames:  151\n",
            "FPS:  24.0\n",
            "Video duration: 6.29 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 198/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0018.mp4\n",
            "Number total of frames:  150\n",
            "FPS:  24.0\n",
            "Video duration: 6.25 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 199/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0020.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  24.0\n",
            "Video duration: 2.46 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 200/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0038.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0038.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0038.mp4\n",
            "Number total of frames:  145\n",
            "FPS:  24.0\n",
            "Video duration: 6.04 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "Checkpoint 200 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 201/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0040.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0040.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0040.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  24.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 202/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0041.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0041.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0041.mp4\n",
            "Number total of frames:  116\n",
            "FPS:  24.0\n",
            "Video duration: 4.83 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 203/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0042.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0042.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0042.mp4\n",
            "Number total of frames:  50\n",
            "FPS:  24.0\n",
            "Video duration: 2.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 204/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0044.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0044.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0044.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  24.0\n",
            "Video duration: 3.75 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 205/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0046.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0046.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0046.mp4\n",
            "Number total of frames:  64\n",
            "FPS:  24.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 206/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0027_0049.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0027_0049.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0027_0049.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  24.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 1920\n",
            "Frame height: 1040\n",
            "-----------------------------------------------\n",
            "Processing file 207/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0028_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0028_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0028_0003.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  25.0\n",
            "Video duration: 3.52 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 208/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0028_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0028_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0028_0008.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  25.0\n",
            "Video duration: 3.68 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 209/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0028_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0028_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0028_0011.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  25.0\n",
            "Video duration: 3.04 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 210/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0028_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0028_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0028_0013.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  25.0\n",
            "Video duration: 2.36 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 211/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0028_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0028_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0028_0021.mp4\n",
            "Number total of frames:  108\n",
            "FPS:  25.0\n",
            "Video duration: 4.32 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 212/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0029_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0029_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0029_0010.mp4\n",
            "Number total of frames:  197\n",
            "FPS:  24.0\n",
            "Video duration: 8.21 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 213/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0029_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0029_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0029_0012.mp4\n",
            "Number total of frames:  38\n",
            "FPS:  24.0\n",
            "Video duration: 1.58 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 214/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0029_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0029_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0029_0018.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  24.0\n",
            "Video duration: 3.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 215/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0029_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0029_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0029_0021.mp4\n",
            "Number total of frames:  155\n",
            "FPS:  24.0\n",
            "Video duration: 6.46 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 216/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0029_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0029_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0029_0022.mp4\n",
            "Number total of frames:  119\n",
            "FPS:  24.0\n",
            "Video duration: 4.96 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 217/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0029_0024.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0029_0024.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0029_0024.mp4\n",
            "Number total of frames:  207\n",
            "FPS:  24.0\n",
            "Video duration: 8.62 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 218/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0008.mp4\n",
            "Number total of frames:  111\n",
            "FPS:  25.0\n",
            "Video duration: 4.44 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 219/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0009.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  25.0\n",
            "Video duration: 3.6 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 220/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0014.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  25.0\n",
            "Video duration: 2.28 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 221/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0016.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  25.0\n",
            "Video duration: 3.76 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 222/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0017.mp4\n",
            "Number total of frames:  145\n",
            "FPS:  25.0\n",
            "Video duration: 5.8 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 223/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0018.mp4\n",
            "Number total of frames:  161\n",
            "FPS:  25.0\n",
            "Video duration: 6.44 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 224/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0020.mp4\n",
            "Number total of frames:  366\n",
            "FPS:  25.0\n",
            "Video duration: 14.64 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 225/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0021.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  25.0\n",
            "Video duration: 2.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "Checkpoint 225 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 226/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0033.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0033.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0033.mp4\n",
            "Number total of frames:  115\n",
            "FPS:  25.0\n",
            "Video duration: 4.6 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 227/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0034.mp4\n",
            "Number total of frames:  246\n",
            "FPS:  25.0\n",
            "Video duration: 9.84 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 228/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0030_0036.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0030_0036.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0030_0036.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  25.0\n",
            "Video duration: 2.48 s\n",
            "Frame width: 1920\n",
            "Frame height: 816\n",
            "-----------------------------------------------\n",
            "Processing file 229/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0004.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  24.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 230/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0005.mp4\n",
            "Number total of frames:  184\n",
            "FPS:  24.0\n",
            "Video duration: 7.67 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 231/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0012.mp4\n",
            "Number total of frames:  148\n",
            "FPS:  24.0\n",
            "Video duration: 6.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 232/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0014.mp4\n",
            "Number total of frames:  124\n",
            "FPS:  24.0\n",
            "Video duration: 5.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 233/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0017.mp4\n",
            "Number total of frames:  155\n",
            "FPS:  24.0\n",
            "Video duration: 6.46 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 234/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0019.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  24.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 235/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0028.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0028.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0028.mp4\n",
            "Number total of frames:  158\n",
            "FPS:  24.0\n",
            "Video duration: 6.58 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 236/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0030.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0030.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0030.mp4\n",
            "Number total of frames:  106\n",
            "FPS:  24.0\n",
            "Video duration: 4.42 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 237/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0031.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0031.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0031.mp4\n",
            "Number total of frames:  127\n",
            "FPS:  24.0\n",
            "Video duration: 5.29 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 238/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0031_0032.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0031_0032.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0031_0032.mp4\n",
            "Number total of frames:  98\n",
            "FPS:  24.0\n",
            "Video duration: 4.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 239/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0032_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0032_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0032_0001.mp4\n",
            "Number total of frames:  115\n",
            "FPS:  24.0\n",
            "Video duration: 4.79 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 240/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0032_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0032_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0032_0004.mp4\n",
            "Number total of frames:  173\n",
            "FPS:  24.0\n",
            "Video duration: 7.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 241/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0032_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0032_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0032_0005.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  24.0\n",
            "Video duration: 3.38 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 242/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0032_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0032_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0032_0014.mp4\n",
            "Number total of frames:  221\n",
            "FPS:  24.0\n",
            "Video duration: 9.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 243/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0032_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0032_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0032_0017.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  24.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 244/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0032_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0032_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0032_0018.mp4\n",
            "Number total of frames:  61\n",
            "FPS:  24.0\n",
            "Video duration: 2.54 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 245/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0032_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0032_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0032_0021.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  24.0\n",
            "Video duration: 3.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 246/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0032_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0032_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0032_0023.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  24.0\n",
            "Video duration: 3.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 247/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0033_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0033_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0033_0004.mp4\n",
            "Number total of frames:  259\n",
            "FPS:  24.0\n",
            "Video duration: 10.79 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 248/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0033_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0033_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0033_0005.mp4\n",
            "Number total of frames:  109\n",
            "FPS:  24.0\n",
            "Video duration: 4.54 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 249/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0034_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0034_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0034_0014.mp4\n",
            "Number total of frames:  147\n",
            "FPS:  24.0\n",
            "Video duration: 6.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "-----------------------------------------------\n",
            "Processing file 250/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0034_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0034_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0034_0016.mp4\n",
            "Number total of frames:  82\n",
            "FPS:  24.0\n",
            "Video duration: 3.42 s\n",
            "Frame width: 1920\n",
            "Frame height: 808\n",
            "Checkpoint 250 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 251/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0008.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  24.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 252/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0014.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  24.0\n",
            "Video duration: 3.83 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 253/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0015.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  24.0\n",
            "Video duration: 3.38 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 254/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0017.mp4\n",
            "Number total of frames:  114\n",
            "FPS:  24.0\n",
            "Video duration: 4.75 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 255/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0019.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  24.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 256/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0020.mp4\n",
            "Number total of frames:  106\n",
            "FPS:  24.0\n",
            "Video duration: 4.42 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 257/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0022.mp4\n",
            "Number total of frames:  47\n",
            "FPS:  24.0\n",
            "Video duration: 1.96 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 258/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0023.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  24.0\n",
            "Video duration: 3.21 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 259/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0024.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0024.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0024.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  24.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 260/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0026.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0026.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0026.mp4\n",
            "Number total of frames:  186\n",
            "FPS:  24.0\n",
            "Video duration: 7.75 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 261/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0028.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0028.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0028.mp4\n",
            "Number total of frames:  47\n",
            "FPS:  24.0\n",
            "Video duration: 1.96 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 262/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0035_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0035_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0035_0034.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  24.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 848\n",
            "Frame height: 352\n",
            "-----------------------------------------------\n",
            "Processing file 263/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0036_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0036_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0036_0002.mp4\n",
            "Number total of frames:  82\n",
            "FPS:  24.0\n",
            "Video duration: 3.42 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 264/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0036_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0036_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0036_0003.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  24.0\n",
            "Video duration: 4.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 265/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0036_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0036_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0036_0013.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  24.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 266/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0036_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0036_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0036_0018.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  24.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 267/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0036_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0036_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0036_0022.mp4\n",
            "Number total of frames:  210\n",
            "FPS:  24.0\n",
            "Video duration: 8.75 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 268/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0036_0032.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0036_0032.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0036_0032.mp4\n",
            "Number total of frames:  172\n",
            "FPS:  24.0\n",
            "Video duration: 7.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 269/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0037_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0037_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0037_0008.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  24.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 270/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0037_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0037_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0037_0010.mp4\n",
            "Number total of frames:  41\n",
            "FPS:  24.0\n",
            "Video duration: 1.71 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 271/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0037_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0037_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0037_0012.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  24.0\n",
            "Video duration: 2.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 272/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0037_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0037_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0037_0013.mp4\n",
            "Number total of frames:  162\n",
            "FPS:  24.0\n",
            "Video duration: 6.75 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 273/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0001.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  24.0\n",
            "Video duration: 3.71 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 274/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0004.mp4\n",
            "Number total of frames:  102\n",
            "FPS:  24.0\n",
            "Video duration: 4.25 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 275/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0008.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  24.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "Checkpoint 275 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 276/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0016.mp4\n",
            "Number total of frames:  39\n",
            "FPS:  24.0\n",
            "Video duration: 1.62 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 277/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0017.mp4\n",
            "Number total of frames:  104\n",
            "FPS:  24.0\n",
            "Video duration: 4.33 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 278/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0021.mp4\n",
            "Number total of frames:  110\n",
            "FPS:  24.0\n",
            "Video duration: 4.58 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 279/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0025.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0025.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0025.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  24.0\n",
            "Video duration: 2.62 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 280/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0027.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0027.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0027.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  24.0\n",
            "Video duration: 3.5 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 281/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0031.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0031.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0031.mp4\n",
            "Number total of frames:  22\n",
            "FPS:  24.0\n",
            "Video duration: 0.92 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 282/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0039.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0039.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0039.mp4\n",
            "Number total of frames:  38\n",
            "FPS:  24.0\n",
            "Video duration: 1.58 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 283/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0044.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0044.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0044.mp4\n",
            "Number total of frames:  18\n",
            "FPS:  24.0\n",
            "Video duration: 0.75 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 284/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0038_0048.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0038_0048.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0038_0048.mp4\n",
            "Number total of frames:  34\n",
            "FPS:  24.0\n",
            "Video duration: 1.42 s\n",
            "Frame width: 864\n",
            "Frame height: 486\n",
            "-----------------------------------------------\n",
            "Processing file 285/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0039_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0039_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0039_0003.mp4\n",
            "Number total of frames:  203\n",
            "FPS:  24.0\n",
            "Video duration: 8.46 s\n",
            "Frame width: 1080\n",
            "Frame height: 422\n",
            "-----------------------------------------------\n",
            "Processing file 286/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0039_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0039_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0039_0007.mp4\n",
            "Number total of frames:  139\n",
            "FPS:  24.0\n",
            "Video duration: 5.79 s\n",
            "Frame width: 1080\n",
            "Frame height: 422\n",
            "-----------------------------------------------\n",
            "Processing file 287/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0004.mp4\n",
            "Number total of frames:  44\n",
            "FPS:  24.0\n",
            "Video duration: 1.83 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 288/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0005.mp4\n",
            "Number total of frames:  37\n",
            "FPS:  24.0\n",
            "Video duration: 1.54 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 289/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0006.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  24.0\n",
            "Video duration: 2.71 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 290/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0012.mp4\n",
            "Number total of frames:  22\n",
            "FPS:  24.0\n",
            "Video duration: 0.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 291/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0015.mp4\n",
            "Number total of frames:  123\n",
            "FPS:  24.0\n",
            "Video duration: 5.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 292/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0016.mp4\n",
            "Number total of frames:  36\n",
            "FPS:  24.0\n",
            "Video duration: 1.5 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 293/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0028.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0028.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0028.mp4\n",
            "Number total of frames:  108\n",
            "FPS:  24.0\n",
            "Video duration: 4.5 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 294/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0029.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0029.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0029.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  24.0\n",
            "Video duration: 3.38 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 295/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0031.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0031.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0031.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  24.0\n",
            "Video duration: 2.75 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 296/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0034.mp4\n",
            "Number total of frames:  186\n",
            "FPS:  24.0\n",
            "Video duration: 7.75 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 297/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0035.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0035.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0035.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  24.0\n",
            "Video duration: 2.83 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 298/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0038.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0038.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0038.mp4\n",
            "Number total of frames:  35\n",
            "FPS:  24.0\n",
            "Video duration: 1.46 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 299/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0047.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0047.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0047.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  24.0\n",
            "Video duration: 4.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 300/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0048.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0048.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0048.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  24.0\n",
            "Video duration: 2.88 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "Checkpoint 300 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 301/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0040_0049.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0040_0049.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0040_0049.mp4\n",
            "Number total of frames:  151\n",
            "FPS:  24.0\n",
            "Video duration: 6.29 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 302/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0001.mp4\n",
            "Number total of frames:  159\n",
            "FPS:  25.0\n",
            "Video duration: 6.36 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 303/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0009.mp4\n",
            "Number total of frames:  142\n",
            "FPS:  25.0\n",
            "Video duration: 5.68 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 304/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0010.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  25.0\n",
            "Video duration: 2.16 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 305/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0012.mp4\n",
            "Number total of frames:  180\n",
            "FPS:  25.0\n",
            "Video duration: 7.2 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 306/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0013.mp4\n",
            "Number total of frames:  176\n",
            "FPS:  25.0\n",
            "Video duration: 7.04 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 307/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0015.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  25.0\n",
            "Video duration: 3.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 308/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0018.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  25.0\n",
            "Video duration: 2.36 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 309/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0022.mp4\n",
            "Number total of frames:  47\n",
            "FPS:  25.0\n",
            "Video duration: 1.88 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 310/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0023.mp4\n",
            "Number total of frames:  232\n",
            "FPS:  25.0\n",
            "Video duration: 9.28 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 311/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0028.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0028.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0028.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  25.0\n",
            "Video duration: 3.24 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 312/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0041_0029.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0041_0029.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0041_0029.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  25.0\n",
            "Video duration: 3.84 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 313/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0042_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0042_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0042_0004.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  25.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 314/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0042_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0042_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0042_0005.mp4\n",
            "Number total of frames:  52\n",
            "FPS:  25.0\n",
            "Video duration: 2.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 315/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0042_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0042_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0042_0009.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  25.0\n",
            "Video duration: 2.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 316/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0042_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0042_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0042_0012.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  25.0\n",
            "Video duration: 3.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 317/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0042_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0042_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0042_0015.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  25.0\n",
            "Video duration: 3.24 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 318/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0002.mp4\n",
            "Number total of frames:  142\n",
            "FPS:  25.0\n",
            "Video duration: 5.68 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 319/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0003.mp4\n",
            "Number total of frames:  171\n",
            "FPS:  25.0\n",
            "Video duration: 6.84 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 320/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0008.mp4\n",
            "Number total of frames:  142\n",
            "FPS:  25.0\n",
            "Video duration: 5.68 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 321/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0011.mp4\n",
            "Number total of frames:  107\n",
            "FPS:  25.0\n",
            "Video duration: 4.28 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 322/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0012.mp4\n",
            "Number total of frames:  33\n",
            "FPS:  25.0\n",
            "Video duration: 1.32 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 323/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0016.mp4\n",
            "Number total of frames:  154\n",
            "FPS:  25.0\n",
            "Video duration: 6.16 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 324/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0018.mp4\n",
            "Number total of frames:  223\n",
            "FPS:  25.0\n",
            "Video duration: 8.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 325/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0019.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  25.0\n",
            "Video duration: 3.24 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "Checkpoint 325 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 326/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0020.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  25.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 327/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0022.mp4\n",
            "Number total of frames:  91\n",
            "FPS:  25.0\n",
            "Video duration: 3.64 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 328/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0027.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0027.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0027.mp4\n",
            "Number total of frames:  143\n",
            "FPS:  25.0\n",
            "Video duration: 5.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 329/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0034.mp4\n",
            "Number total of frames:  51\n",
            "FPS:  25.0\n",
            "Video duration: 2.04 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 330/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0038.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0038.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0038.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  25.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 331/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0039.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0039.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0039.mp4\n",
            "Number total of frames:  31\n",
            "FPS:  25.0\n",
            "Video duration: 1.24 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 332/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0040.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0040.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0040.mp4\n",
            "Number total of frames:  41\n",
            "FPS:  25.0\n",
            "Video duration: 1.64 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 333/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0045.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0045.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0045.mp4\n",
            "Number total of frames:  145\n",
            "FPS:  25.0\n",
            "Video duration: 5.8 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 334/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0046.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0046.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0046.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  25.0\n",
            "Video duration: 3.56 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 335/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0049.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0049.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0049.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  25.0\n",
            "Video duration: 2.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 336/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0050.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0050.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0050.mp4\n",
            "Number total of frames:  171\n",
            "FPS:  25.0\n",
            "Video duration: 6.84 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 337/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0051.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0051.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0051.mp4\n",
            "Number total of frames:  123\n",
            "FPS:  25.0\n",
            "Video duration: 4.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 338/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0053.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0053.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0053.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  25.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 339/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0056.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0056.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0056.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  25.0\n",
            "Video duration: 3.32 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 340/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0060.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0060.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0060.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  25.0\n",
            "Video duration: 3.68 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 341/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0043_0063.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0043_0063.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0043_0063.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  25.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 342/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0044_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0044_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0044_0001.mp4\n",
            "Number total of frames:  209\n",
            "FPS:  25.0\n",
            "Video duration: 8.36 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 343/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0044_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0044_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0044_0008.mp4\n",
            "Number total of frames:  100\n",
            "FPS:  25.0\n",
            "Video duration: 4.0 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 344/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0002.mp4\n",
            "Number total of frames:  91\n",
            "FPS:  25.0\n",
            "Video duration: 3.64 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 345/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0003.mp4\n",
            "Number total of frames:  116\n",
            "FPS:  25.0\n",
            "Video duration: 4.64 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 346/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0007.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  25.0\n",
            "Video duration: 2.28 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 347/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0008.mp4\n",
            "Number total of frames:  51\n",
            "FPS:  25.0\n",
            "Video duration: 2.04 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 348/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0010.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  25.0\n",
            "Video duration: 3.88 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 349/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0015.mp4\n",
            "Number total of frames:  85\n",
            "FPS:  25.0\n",
            "Video duration: 3.4 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 350/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0017.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0017.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0017.mp4\n",
            "Number total of frames:  125\n",
            "FPS:  25.0\n",
            "Video duration: 5.0 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "Checkpoint 350 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 351/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0018.mp4\n",
            "Number total of frames:  153\n",
            "FPS:  25.0\n",
            "Video duration: 6.12 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 352/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0021.mp4\n",
            "Number total of frames:  144\n",
            "FPS:  25.0\n",
            "Video duration: 5.76 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 353/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0024.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0024.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0024.mp4\n",
            "Number total of frames:  67\n",
            "FPS:  25.0\n",
            "Video duration: 2.68 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 354/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0025.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0025.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0025.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  25.0\n",
            "Video duration: 3.88 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 355/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0027.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0027.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0027.mp4\n",
            "Number total of frames:  46\n",
            "FPS:  25.0\n",
            "Video duration: 1.84 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 356/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0033.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0033.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0033.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  25.0\n",
            "Video duration: 3.8 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 357/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0034.mp4\n",
            "Number total of frames:  125\n",
            "FPS:  25.0\n",
            "Video duration: 5.0 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 358/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0035.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0035.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0035.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  25.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 359/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0042.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0042.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0042.mp4\n",
            "Number total of frames:  149\n",
            "FPS:  25.0\n",
            "Video duration: 5.96 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 360/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0043.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0043.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0043.mp4\n",
            "Number total of frames:  173\n",
            "FPS:  25.0\n",
            "Video duration: 6.92 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 361/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0049.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0049.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0049.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  25.0\n",
            "Video duration: 3.68 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 362/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0055.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0055.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0055.mp4\n",
            "Number total of frames:  104\n",
            "FPS:  25.0\n",
            "Video duration: 4.16 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 363/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0056.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0056.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0056.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  25.0\n",
            "Video duration: 3.84 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 364/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0058.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0058.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0058.mp4\n",
            "Number total of frames:  169\n",
            "FPS:  25.0\n",
            "Video duration: 6.76 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 365/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0062.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0062.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0062.mp4\n",
            "Number total of frames:  115\n",
            "FPS:  25.0\n",
            "Video duration: 4.6 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 366/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0063.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0063.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0063.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  25.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 367/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0065.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0065.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0065.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  25.0\n",
            "Video duration: 2.88 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 368/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0072.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0072.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0072.mp4\n",
            "Number total of frames:  186\n",
            "FPS:  25.0\n",
            "Video duration: 7.44 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 369/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0079.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0079.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0079.mp4\n",
            "Number total of frames:  218\n",
            "FPS:  25.0\n",
            "Video duration: 8.72 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 370/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0083.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0083.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0083.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  25.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 371/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0084.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0084.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0084.mp4\n",
            "Number total of frames:  152\n",
            "FPS:  25.0\n",
            "Video duration: 6.08 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 372/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0085.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0085.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0085.mp4\n",
            "Number total of frames:  46\n",
            "FPS:  25.0\n",
            "Video duration: 1.84 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 373/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0086.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0086.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0086.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  25.0\n",
            "Video duration: 4.04 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 374/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0087.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0087.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0087.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  25.0\n",
            "Video duration: 2.36 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 375/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0099.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0099.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0099.mp4\n",
            "Number total of frames:  193\n",
            "FPS:  25.0\n",
            "Video duration: 7.72 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "Checkpoint 375 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 376/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0101.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0101.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0101.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  25.0\n",
            "Video duration: 3.72 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 377/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0102.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0102.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0102.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  25.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 378/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0103.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0103.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0103.mp4\n",
            "Number total of frames:  102\n",
            "FPS:  25.0\n",
            "Video duration: 4.08 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 379/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0104.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0104.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0104.mp4\n",
            "Number total of frames:  134\n",
            "FPS:  25.0\n",
            "Video duration: 5.36 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 380/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0045_0105.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0045_0105.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0045_0105.mp4\n",
            "Number total of frames:  26\n",
            "FPS:  25.0\n",
            "Video duration: 1.04 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 381/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0003.mp4\n",
            "Number total of frames:  100\n",
            "FPS:  25.0\n",
            "Video duration: 4.0 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 382/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0004.mp4\n",
            "Number total of frames:  124\n",
            "FPS:  25.0\n",
            "Video duration: 4.96 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 383/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0006.mp4\n",
            "Number total of frames:  85\n",
            "FPS:  25.0\n",
            "Video duration: 3.4 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 384/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0008.mp4\n",
            "Number total of frames:  46\n",
            "FPS:  25.0\n",
            "Video duration: 1.84 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 385/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0009.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  25.0\n",
            "Video duration: 3.24 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 386/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0013.mp4\n",
            "Number total of frames:  127\n",
            "FPS:  25.0\n",
            "Video duration: 5.08 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 387/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0014.mp4\n",
            "Number total of frames:  142\n",
            "FPS:  25.0\n",
            "Video duration: 5.68 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 388/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0015.mp4\n",
            "Number total of frames:  102\n",
            "FPS:  25.0\n",
            "Video duration: 4.08 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 389/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0016.mp4\n",
            "Number total of frames:  107\n",
            "FPS:  25.0\n",
            "Video duration: 4.28 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 390/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0018.mp4\n",
            "Number total of frames:  98\n",
            "FPS:  25.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 391/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0021.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  25.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 392/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0033.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0033.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0033.mp4\n",
            "Number total of frames:  242\n",
            "FPS:  25.0\n",
            "Video duration: 9.68 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 393/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0036.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0036.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0036.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  25.0\n",
            "Video duration: 3.36 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 394/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0041.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0041.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0041.mp4\n",
            "Number total of frames:  133\n",
            "FPS:  25.0\n",
            "Video duration: 5.32 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 395/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0049.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0049.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0049.mp4\n",
            "Number total of frames:  108\n",
            "FPS:  25.0\n",
            "Video duration: 4.32 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 396/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0051.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0051.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0051.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  25.0\n",
            "Video duration: 3.44 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 397/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0052.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0052.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0052.mp4\n",
            "Number total of frames:  51\n",
            "FPS:  25.0\n",
            "Video duration: 2.04 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 398/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0046_0062.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0046_0062.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0046_0062.mp4\n",
            "Number total of frames:  191\n",
            "FPS:  25.0\n",
            "Video duration: 7.64 s\n",
            "Frame width: 576\n",
            "Frame height: 432\n",
            "-----------------------------------------------\n",
            "Processing file 399/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0001.mp4\n",
            "Number total of frames:  40\n",
            "FPS:  25.0\n",
            "Video duration: 1.6 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 400/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0003.mp4\n",
            "Number total of frames:  130\n",
            "FPS:  25.0\n",
            "Video duration: 5.2 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "Checkpoint 400 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 401/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0006.mp4\n",
            "Number total of frames:  42\n",
            "FPS:  25.0\n",
            "Video duration: 1.68 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 402/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0007.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  25.0\n",
            "Video duration: 2.72 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 403/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0009.mp4\n",
            "Number total of frames:  38\n",
            "FPS:  25.0\n",
            "Video duration: 1.52 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 404/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0010.mp4\n",
            "Number total of frames:  52\n",
            "FPS:  25.0\n",
            "Video duration: 2.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 405/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0012.mp4\n",
            "Number total of frames:  139\n",
            "FPS:  25.0\n",
            "Video duration: 5.56 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 406/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0019.mp4\n",
            "Number total of frames:  36\n",
            "FPS:  25.0\n",
            "Video duration: 1.44 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 407/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0022.mp4\n",
            "Number total of frames:  120\n",
            "FPS:  25.0\n",
            "Video duration: 4.8 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 408/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0023.mp4\n",
            "Number total of frames:  31\n",
            "FPS:  25.0\n",
            "Video duration: 1.24 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 409/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0037.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0037.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0037.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  25.0\n",
            "Video duration: 2.28 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 410/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0038.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0038.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0038.mp4\n",
            "Number total of frames:  73\n",
            "FPS:  25.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 411/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0050.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0050.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0050.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  25.0\n",
            "Video duration: 3.48 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 412/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0053.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0053.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0053.mp4\n",
            "Number total of frames:  67\n",
            "FPS:  25.0\n",
            "Video duration: 2.68 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 413/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0055.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0055.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0055.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  25.0\n",
            "Video duration: 3.32 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 414/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0057.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0057.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0057.mp4\n",
            "Number total of frames:  37\n",
            "FPS:  25.0\n",
            "Video duration: 1.48 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 415/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0058.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0058.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0058.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  25.0\n",
            "Video duration: 2.96 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 416/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0060.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0060.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0060.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  25.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 417/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0061.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0061.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0061.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  25.0\n",
            "Video duration: 3.04 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 418/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0064.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0064.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0064.mp4\n",
            "Number total of frames:  128\n",
            "FPS:  25.0\n",
            "Video duration: 5.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 419/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0068.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0068.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0068.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  25.0\n",
            "Video duration: 3.36 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 420/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0069.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0069.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0069.mp4\n",
            "Number total of frames:  91\n",
            "FPS:  25.0\n",
            "Video duration: 3.64 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 421/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0073.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0073.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0073.mp4\n",
            "Number total of frames:  85\n",
            "FPS:  25.0\n",
            "Video duration: 3.4 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 422/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0047_0075.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0047_0075.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0047_0075.mp4\n",
            "Number total of frames:  116\n",
            "FPS:  25.0\n",
            "Video duration: 4.64 s\n",
            "Frame width: 1920\n",
            "Frame height: 806\n",
            "-----------------------------------------------\n",
            "Processing file 423/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0048_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0048_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0048_0013.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  25.0\n",
            "Video duration: 2.48 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 424/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0048_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0048_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0048_0016.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  25.0\n",
            "Video duration: 3.88 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 425/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0048_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0048_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0048_0019.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  25.0\n",
            "Video duration: 3.48 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "Checkpoint 425 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 426/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0048_0030.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0048_0030.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0048_0030.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  25.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 427/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0049_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0049_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0049_0004.mp4\n",
            "Number total of frames:  112\n",
            "FPS:  25.0\n",
            "Video duration: 4.48 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 428/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0049_0008.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0049_0008.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0049_0008.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  25.0\n",
            "Video duration: 2.12 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 429/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0049_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0049_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0049_0010.mp4\n",
            "Number total of frames:  61\n",
            "FPS:  25.0\n",
            "Video duration: 2.44 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 430/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0049_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0049_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0049_0012.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  25.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 431/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0049_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0049_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0049_0015.mp4\n",
            "Number total of frames:  82\n",
            "FPS:  25.0\n",
            "Video duration: 3.28 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 432/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0049_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0049_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0049_0018.mp4\n",
            "Number total of frames:  67\n",
            "FPS:  25.0\n",
            "Video duration: 2.68 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 433/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0050_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0050_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0050_0003.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  25.0\n",
            "Video duration: 3.24 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 434/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0050_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0050_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0050_0005.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  25.0\n",
            "Video duration: 2.88 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 435/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0050_0013.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0050_0013.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0050_0013.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  25.0\n",
            "Video duration: 2.24 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 436/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0009.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  25.0\n",
            "Video duration: 3.6 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 437/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0010.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  25.0\n",
            "Video duration: 3.56 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 438/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0011.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  25.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 439/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0014.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0014.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0014.mp4\n",
            "Number total of frames:  118\n",
            "FPS:  25.0\n",
            "Video duration: 4.72 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 440/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0022.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  25.0\n",
            "Video duration: 3.52 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 441/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0040.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0040.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0040.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  25.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 442/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0044.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0044.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0044.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  25.0\n",
            "Video duration: 2.64 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 443/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0048.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0048.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0048.mp4\n",
            "Number total of frames:  98\n",
            "FPS:  25.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 444/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0050.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0050.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0050.mp4\n",
            "Number total of frames:  100\n",
            "FPS:  25.0\n",
            "Video duration: 4.0 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 445/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0052.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0052.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0052.mp4\n",
            "Number total of frames:  43\n",
            "FPS:  25.0\n",
            "Video duration: 1.72 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 446/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0054.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0054.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0054.mp4\n",
            "Number total of frames:  128\n",
            "FPS:  25.0\n",
            "Video duration: 5.12 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 447/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0056.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0056.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0056.mp4\n",
            "Number total of frames:  39\n",
            "FPS:  25.0\n",
            "Video duration: 1.56 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 448/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0057.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0057.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0057.mp4\n",
            "Number total of frames:  61\n",
            "FPS:  25.0\n",
            "Video duration: 2.44 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 449/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0058.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0058.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0058.mp4\n",
            "Number total of frames:  43\n",
            "FPS:  25.0\n",
            "Video duration: 1.72 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 450/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0066.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0066.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0066.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  25.0\n",
            "Video duration: 3.8 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "Checkpoint 450 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 451/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0067.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0067.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0067.mp4\n",
            "Number total of frames:  52\n",
            "FPS:  25.0\n",
            "Video duration: 2.08 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 452/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0070.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0070.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0070.mp4\n",
            "Number total of frames:  200\n",
            "FPS:  25.0\n",
            "Video duration: 8.0 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 453/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0051_0071.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0051_0071.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0051_0071.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  25.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 454/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0001.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  25.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 455/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0011.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  25.0\n",
            "Video duration: 3.84 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 456/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0016.mp4\n",
            "Number total of frames:  161\n",
            "FPS:  25.0\n",
            "Video duration: 6.44 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 457/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0019.mp4\n",
            "Number total of frames:  109\n",
            "FPS:  25.0\n",
            "Video duration: 4.36 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 458/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0020.mp4\n",
            "Number total of frames:  147\n",
            "FPS:  25.0\n",
            "Video duration: 5.88 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 459/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0021.mp4\n",
            "Number total of frames:  121\n",
            "FPS:  25.0\n",
            "Video duration: 4.84 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 460/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0022.mp4\n",
            "Number total of frames:  91\n",
            "FPS:  25.0\n",
            "Video duration: 3.64 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 461/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0023.mp4\n",
            "Number total of frames:  48\n",
            "FPS:  25.0\n",
            "Video duration: 1.92 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 462/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0024.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0024.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0024.mp4\n",
            "Number total of frames:  135\n",
            "FPS:  25.0\n",
            "Video duration: 5.4 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 463/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0052_0031.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0052_0031.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0052_0031.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  25.0\n",
            "Video duration: 2.28 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 464/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0002.mp4\n",
            "Number total of frames:  154\n",
            "FPS:  25.0\n",
            "Video duration: 6.16 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 465/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0005.mp4\n",
            "Number total of frames:  107\n",
            "FPS:  25.0\n",
            "Video duration: 4.28 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 466/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0015.mp4\n",
            "Number total of frames:  121\n",
            "FPS:  25.0\n",
            "Video duration: 4.84 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 467/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0016.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  25.0\n",
            "Video duration: 2.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 468/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0021.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  25.0\n",
            "Video duration: 3.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 469/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0022.mp4\n",
            "Number total of frames:  178\n",
            "FPS:  25.0\n",
            "Video duration: 7.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 470/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0023.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0023.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0023.mp4\n",
            "Number total of frames:  200\n",
            "FPS:  25.0\n",
            "Video duration: 8.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 471/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0027.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0027.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0027.mp4\n",
            "Number total of frames:  55\n",
            "FPS:  25.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 472/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0029.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0029.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0029.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  25.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 473/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0032.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0032.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0032.mp4\n",
            "Number total of frames:  127\n",
            "FPS:  25.0\n",
            "Video duration: 5.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 474/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0034.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  25.0\n",
            "Video duration: 3.04 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 475/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0040.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0040.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0040.mp4\n",
            "Number total of frames:  113\n",
            "FPS:  25.0\n",
            "Video duration: 4.52 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "Checkpoint 475 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 476/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0043.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0043.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0043.mp4\n",
            "Number total of frames:  145\n",
            "FPS:  25.0\n",
            "Video duration: 5.8 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 477/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0045.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0045.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0045.mp4\n",
            "Number total of frames:  156\n",
            "FPS:  25.0\n",
            "Video duration: 6.24 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 478/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0055.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0055.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0055.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  25.0\n",
            "Video duration: 3.48 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 479/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0058.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0058.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0058.mp4\n",
            "Number total of frames:  135\n",
            "FPS:  25.0\n",
            "Video duration: 5.4 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 480/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0053_0061.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0053_0061.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0053_0061.mp4\n",
            "Number total of frames:  150\n",
            "FPS:  25.0\n",
            "Video duration: 6.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 481/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0003.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  24.0\n",
            "Video duration: 2.88 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 482/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0005.mp4\n",
            "Number total of frames:  40\n",
            "FPS:  24.0\n",
            "Video duration: 1.67 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 483/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0012.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  24.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 484/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0016.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  24.0\n",
            "Video duration: 3.71 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 485/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0022.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  24.0\n",
            "Video duration: 2.62 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 486/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0024.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0024.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0024.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  24.0\n",
            "Video duration: 3.71 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 487/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0027.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0027.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0027.mp4\n",
            "Number total of frames:  38\n",
            "FPS:  24.0\n",
            "Video duration: 1.58 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 488/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0029.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0029.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0029.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  24.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 489/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0030.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0030.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0030.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  24.0\n",
            "Video duration: 2.62 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 490/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0033.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0033.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0033.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  24.0\n",
            "Video duration: 3.46 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 491/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0034.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0034.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0034.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  24.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 492/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0035.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0035.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0035.mp4\n",
            "Number total of frames:  105\n",
            "FPS:  24.0\n",
            "Video duration: 4.38 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 493/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0042.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0042.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0042.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  24.0\n",
            "Video duration: 4.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 494/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0044.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0044.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0044.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  24.0\n",
            "Video duration: 2.58 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 495/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0054.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0054.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0054.mp4\n",
            "Number total of frames:  103\n",
            "FPS:  24.0\n",
            "Video duration: 4.29 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 496/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0055.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0055.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0055.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  24.0\n",
            "Video duration: 2.25 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 497/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0056.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0056.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0056.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  24.0\n",
            "Video duration: 3.5 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 498/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0061.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0061.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0061.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  24.0\n",
            "Video duration: 2.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 499/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0065.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0065.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0065.mp4\n",
            "Number total of frames:  43\n",
            "FPS:  24.0\n",
            "Video duration: 1.79 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 500/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0067.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0067.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0067.mp4\n",
            "Number total of frames:  100\n",
            "FPS:  24.0\n",
            "Video duration: 4.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "Checkpoint 500 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 501/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0072.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0072.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0072.mp4\n",
            "Number total of frames:  47\n",
            "FPS:  24.0\n",
            "Video duration: 1.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 502/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0073.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0073.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0073.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  24.0\n",
            "Video duration: 4.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 503/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0074.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0074.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0074.mp4\n",
            "Number total of frames:  106\n",
            "FPS:  24.0\n",
            "Video duration: 4.42 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 504/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0076.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0076.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0076.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  24.0\n",
            "Video duration: 2.25 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 505/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0078.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0078.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0078.mp4\n",
            "Number total of frames:  58\n",
            "FPS:  24.0\n",
            "Video duration: 2.42 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 506/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0084.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0084.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0084.mp4\n",
            "Number total of frames:  194\n",
            "FPS:  24.0\n",
            "Video duration: 8.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 507/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0090.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0090.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0090.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  24.0\n",
            "Video duration: 2.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 508/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0091.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0091.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0091.mp4\n",
            "Number total of frames:  97\n",
            "FPS:  24.0\n",
            "Video duration: 4.04 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 509/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0094.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0094.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0094.mp4\n",
            "Number total of frames:  39\n",
            "FPS:  24.0\n",
            "Video duration: 1.62 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 510/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0101.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0101.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0101.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  24.0\n",
            "Video duration: 2.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 511/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0102.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0102.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0102.mp4\n",
            "Number total of frames:  39\n",
            "FPS:  24.0\n",
            "Video duration: 1.62 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 512/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0105.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0105.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0105.mp4\n",
            "Number total of frames:  38\n",
            "FPS:  24.0\n",
            "Video duration: 1.58 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 513/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0107.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0107.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0107.mp4\n",
            "Number total of frames:  154\n",
            "FPS:  24.0\n",
            "Video duration: 6.42 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 514/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0111.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0111.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0111.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  24.0\n",
            "Video duration: 3.33 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 515/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0112.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0112.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0112.mp4\n",
            "Number total of frames:  191\n",
            "FPS:  24.0\n",
            "Video duration: 7.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 516/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0113.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0113.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0113.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  24.0\n",
            "Video duration: 3.71 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 517/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0121.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0121.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0121.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  24.0\n",
            "Video duration: 2.71 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 518/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0122.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0122.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0122.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  24.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 519/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0127.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0127.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0127.mp4\n",
            "Number total of frames:  45\n",
            "FPS:  24.0\n",
            "Video duration: 1.88 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 520/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0129.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0129.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0129.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  24.0\n",
            "Video duration: 3.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 521/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0132.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0132.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0132.mp4\n",
            "Number total of frames:  110\n",
            "FPS:  24.0\n",
            "Video duration: 4.58 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 522/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0138.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0138.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0138.mp4\n",
            "Number total of frames:  73\n",
            "FPS:  24.0\n",
            "Video duration: 3.04 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 523/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0139.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0139.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0139.mp4\n",
            "Number total of frames:  52\n",
            "FPS:  24.0\n",
            "Video duration: 2.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 524/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0142.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0142.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0142.mp4\n",
            "Number total of frames:  51\n",
            "FPS:  24.0\n",
            "Video duration: 2.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 525/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0143.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0143.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0143.mp4\n",
            "Number total of frames:  100\n",
            "FPS:  24.0\n",
            "Video duration: 4.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "Checkpoint 525 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 526/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0146.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0146.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0146.mp4\n",
            "Number total of frames:  26\n",
            "FPS:  24.0\n",
            "Video duration: 1.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 527/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0147.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0147.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0147.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  24.0\n",
            "Video duration: 2.58 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 528/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0149.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0149.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0149.mp4\n",
            "Number total of frames:  183\n",
            "FPS:  24.0\n",
            "Video duration: 7.62 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 529/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0150.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0150.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0150.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  24.0\n",
            "Video duration: 2.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 530/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0151.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0151.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0151.mp4\n",
            "Number total of frames:  109\n",
            "FPS:  24.0\n",
            "Video duration: 4.54 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 531/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0152.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0152.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0152.mp4\n",
            "Number total of frames:  94\n",
            "FPS:  24.0\n",
            "Video duration: 3.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 532/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0154.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0154.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0154.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  24.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 533/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0163.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0163.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0163.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  24.0\n",
            "Video duration: 3.33 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 534/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0165.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0165.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0165.mp4\n",
            "Number total of frames:  79\n",
            "FPS:  24.0\n",
            "Video duration: 3.29 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 535/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0171.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0171.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0171.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  24.0\n",
            "Video duration: 2.21 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 536/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0175.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0175.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0175.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  24.0\n",
            "Video duration: 2.25 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 537/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0177.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0177.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0177.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  24.0\n",
            "Video duration: 2.88 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 538/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0181.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0181.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0181.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  24.0\n",
            "Video duration: 2.75 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 539/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0054_0182.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0054_0182.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0054_0182.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  24.0\n",
            "Video duration: 3.33 s\n",
            "Frame width: 1280\n",
            "Frame height: 720\n",
            "-----------------------------------------------\n",
            "Processing file 540/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0055_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0055_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0055_0001.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  25.0\n",
            "Video duration: 2.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 541/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0055_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0055_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0055_0012.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  25.0\n",
            "Video duration: 3.52 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 542/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0055_0016.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0055_0016.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0055_0016.mp4\n",
            "Number total of frames:  43\n",
            "FPS:  25.0\n",
            "Video duration: 1.72 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 543/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0055_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0055_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0055_0022.mp4\n",
            "Number total of frames:  39\n",
            "FPS:  25.0\n",
            "Video duration: 1.56 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 544/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0055_0029.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0055_0029.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0055_0029.mp4\n",
            "Number total of frames:  49\n",
            "FPS:  25.0\n",
            "Video duration: 1.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 545/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0055_0035.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0055_0035.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0055_0035.mp4\n",
            "Number total of frames:  38\n",
            "FPS:  25.0\n",
            "Video duration: 1.52 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 546/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0001.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  24.0\n",
            "Video duration: 2.83 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 547/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0005.mp4\n",
            "Number total of frames:  143\n",
            "FPS:  24.0\n",
            "Video duration: 5.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 548/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0019.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0019.mp4\n",
            "Number total of frames:  82\n",
            "FPS:  24.0\n",
            "Video duration: 3.42 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 549/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0021.mp4\n",
            "Number total of frames:  49\n",
            "FPS:  24.0\n",
            "Video duration: 2.04 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 550/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0027.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0027.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0027.mp4\n",
            "Number total of frames:  40\n",
            "FPS:  24.0\n",
            "Video duration: 1.67 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "Checkpoint 550 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 551/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0030.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0030.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0030.mp4\n",
            "Number total of frames:  52\n",
            "FPS:  24.0\n",
            "Video duration: 2.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 552/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0032.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0032.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0032.mp4\n",
            "Number total of frames:  23\n",
            "FPS:  24.0\n",
            "Video duration: 0.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 553/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0036.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0036.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0036.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  24.0\n",
            "Video duration: 2.83 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 554/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0039.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0039.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0039.mp4\n",
            "Number total of frames:  39\n",
            "FPS:  24.0\n",
            "Video duration: 1.62 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 555/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0044.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0044.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0044.mp4\n",
            "Number total of frames:  46\n",
            "FPS:  24.0\n",
            "Video duration: 1.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 556/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0045.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0045.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0045.mp4\n",
            "Number total of frames:  36\n",
            "FPS:  24.0\n",
            "Video duration: 1.5 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 557/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0046.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0046.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0046.mp4\n",
            "Number total of frames:  48\n",
            "FPS:  24.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 558/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0052.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0052.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0052.mp4\n",
            "Number total of frames:  122\n",
            "FPS:  24.0\n",
            "Video duration: 5.08 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 559/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0053.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0053.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0053.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  24.0\n",
            "Video duration: 2.33 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 560/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0059.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0059.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0059.mp4\n",
            "Number total of frames:  28\n",
            "FPS:  24.0\n",
            "Video duration: 1.17 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 561/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0061.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0061.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0061.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  24.0\n",
            "Video duration: 2.33 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 562/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0062.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0062.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0062.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  24.0\n",
            "Video duration: 3.58 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 563/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0064.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0064.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0064.mp4\n",
            "Number total of frames:  107\n",
            "FPS:  24.0\n",
            "Video duration: 4.46 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 564/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0066.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0066.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0066.mp4\n",
            "Number total of frames:  161\n",
            "FPS:  24.0\n",
            "Video duration: 6.71 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 565/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0067.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0067.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0067.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  24.0\n",
            "Video duration: 3.12 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 566/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0071.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0071.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0071.mp4\n",
            "Number total of frames:  23\n",
            "FPS:  24.0\n",
            "Video duration: 0.96 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 567/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0072.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0072.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0072.mp4\n",
            "Number total of frames:  102\n",
            "FPS:  24.0\n",
            "Video duration: 4.25 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 568/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0075.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0075.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0075.mp4\n",
            "Number total of frames:  127\n",
            "FPS:  24.0\n",
            "Video duration: 5.29 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 569/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0077.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0077.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0077.mp4\n",
            "Number total of frames:  35\n",
            "FPS:  24.0\n",
            "Video duration: 1.46 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 570/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0078.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0078.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0078.mp4\n",
            "Number total of frames:  46\n",
            "FPS:  24.0\n",
            "Video duration: 1.92 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 571/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0085.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0085.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0085.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  24.0\n",
            "Video duration: 4.0 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 572/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0086.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0086.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0086.mp4\n",
            "Number total of frames:  226\n",
            "FPS:  24.0\n",
            "Video duration: 9.42 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 573/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0056_0087.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0056_0087.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0056_0087.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  24.0\n",
            "Video duration: 2.38 s\n",
            "Frame width: 1280\n",
            "Frame height: 544\n",
            "-----------------------------------------------\n",
            "Processing file 574/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0057_0004.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0057_0004.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0057_0004.mp4\n",
            "Number total of frames:  44\n",
            "FPS:  30.0\n",
            "Video duration: 1.47 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 575/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0057_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0057_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0057_0005.mp4\n",
            "Number total of frames:  49\n",
            "FPS:  30.0\n",
            "Video duration: 1.63 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "Checkpoint 575 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 576/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0057_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0057_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0057_0011.mp4\n",
            "Number total of frames:  129\n",
            "FPS:  30.0\n",
            "Video duration: 4.3 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 577/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0057_0012.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0057_0012.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0057_0012.mp4\n",
            "Number total of frames:  79\n",
            "FPS:  30.0\n",
            "Video duration: 2.63 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 578/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0057_0020.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0057_0020.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0057_0020.mp4\n",
            "Number total of frames:  88\n",
            "FPS:  30.0\n",
            "Video duration: 2.93 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 579/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0057_0022.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0057_0022.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0057_0022.mp4\n",
            "Number total of frames:  45\n",
            "FPS:  30.0\n",
            "Video duration: 1.5 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 580/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0058_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0058_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0058_0006.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  25.0\n",
            "Video duration: 3.24 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 581/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0058_0011.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0058_0011.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0058_0011.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  25.0\n",
            "Video duration: 3.04 s\n",
            "Frame width: 768\n",
            "Frame height: 576\n",
            "-----------------------------------------------\n",
            "Processing file 582/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0059_0001.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0059_0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0059_0001.mp4\n",
            "Number total of frames:  103\n",
            "FPS:  30.0\n",
            "Video duration: 3.43 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 583/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0059_0007.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0059_0007.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0059_0007.mp4\n",
            "Number total of frames:  70\n",
            "FPS:  30.0\n",
            "Video duration: 2.33 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 584/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0059_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0059_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0059_0010.mp4\n",
            "Number total of frames:  50\n",
            "FPS:  30.0\n",
            "Video duration: 1.67 s\n",
            "Frame width: 1920\n",
            "Frame height: 1080\n",
            "-----------------------------------------------\n",
            "Processing file 585/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0002.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0002.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0002.mp4\n",
            "Number total of frames:  47\n",
            "FPS:  30.0\n",
            "Video duration: 1.57 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 586/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0003.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0003.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 587/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0005.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0005.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0005.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  30.0\n",
            "Video duration: 1.87 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 588/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0006.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0006.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0006.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  30.0\n",
            "Video duration: 1.77 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 589/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0009.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0009.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0009.mp4\n",
            "Number total of frames:  37\n",
            "FPS:  30.0\n",
            "Video duration: 1.23 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 590/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0010.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0010.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0010.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  30.0\n",
            "Video duration: 1.9 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 591/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0015.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0015.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0015.mp4\n",
            "Number total of frames:  76\n",
            "FPS:  30.0\n",
            "Video duration: 2.53 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 592/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0018.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0018.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0018.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  30.0\n",
            "Video duration: 1.8 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 593/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0021.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0021.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0021.mp4\n",
            "Number total of frames:  47\n",
            "FPS:  30.0\n",
            "Video duration: 1.57 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 594/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0024.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0024.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0024.mp4\n",
            "Number total of frames:  43\n",
            "FPS:  30.0\n",
            "Video duration: 1.43 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 595/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0026.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0026.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0026.mp4\n",
            "Number total of frames:  73\n",
            "FPS:  30.0\n",
            "Video duration: 2.43 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 596/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0030.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0030.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0030.mp4\n",
            "Number total of frames:  49\n",
            "FPS:  30.0\n",
            "Video duration: 1.63 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 597/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0032.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0032.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0032.mp4\n",
            "Number total of frames:  122\n",
            "FPS:  30.0\n",
            "Video duration: 4.07 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 598/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0036.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0036.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0036.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 599/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0040.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0040.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0040.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  30.0\n",
            "Video duration: 1.87 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "-----------------------------------------------\n",
            "Processing file 600/600\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_resampled/video_0060_0042.wav\n",
            "Video Input: /content/VideoMP4_testing/video_0060_0042.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  video_0060_0042.mp4\n",
            "Number total of frames:  61\n",
            "FPS:  30.0\n",
            "Video duration: 2.03 s\n",
            "Frame width: 1280\n",
            "Frame height: 540\n",
            "Checkpoint 600 saved.\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pkg_resources\n",
        "# Install packages\n",
        "package_names = ['keras_vggface', 'keras_applications', 'batch_face', 'speechbrain']\n",
        "for package_name in package_names:\n",
        "  try:\n",
        "    dist = pkg_resources.get_distribution(package_name)\n",
        "    print(f\"{package_name} is already installed with version {dist.version}\")\n",
        "  except pkg_resources.DistributionNotFound:\n",
        "    print(f\"{package_name} is not installed, installing now...\")\n",
        "    !pip install {package_name}\n",
        "\n",
        "# !pip install --upgrade --force-reinstall keras_vggface\n",
        "# !pip install keras_vggface\n",
        "# !pip install keras_applications\n",
        "# !pip install batch_face\n",
        "\n",
        "# Fix package files\n",
        "!sed -i 's/from keras.utils import layer_utils/from tensorflow.python.keras.utils import layer_utils/' /usr/local/lib/python3.10/dist-packages/keras_vggface/models.py\n",
        "!sed -i 's/from keras.utils.data_utils import get_file/from tensorflow.python.keras.utils.data_utils import get_file/' /usr/local/lib/python3.10/dist-packages/keras_vggface/models.py\n",
        "!sed -i 's/from keras.utils.data_utils import get_file/from tensorflow.python.keras.utils.data_utils import get_file/' /usr/local/lib/python3.10/dist-packages/keras_vggface/utils.py\n",
        "!sed -i 's/from keras.engine.topology import get_source_inputs/from tensorflow.python.keras.utils.layer_utils import get_source_inputs/' /usr/local/lib/python3.10/dist-packages/keras_vggface/models.py\n",
        "\n",
        "# import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from scipy import stats\n",
        "import pickle\n",
        "import sys\n",
        "# import speechbrain\n",
        "import multiprocessing as mp\n",
        "# from select_video_subset import select_video_subset\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category = FutureWarning)\n",
        "\n",
        "# Mount drive\n",
        "from google.colab import drive\n",
        "\n",
        "def is_drive_mounted():\n",
        "    drive_path = '/content/drive'\n",
        "    return os.path.isdir(drive_path) and os.listdir(drive_path)\n",
        "\n",
        "# Mount Google Drive if it is not already mounted\n",
        "if not is_drive_mounted():\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive is mounted now!\")\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")\n",
        "\n",
        "expected_directory = '/content/notebook_modules'\n",
        "\n",
        "# Check if the expected directory or file exists\n",
        "if not os.path.exists(expected_directory):\n",
        "    print(\"Modules directory does not exist, extracting the ZIP file...\")\n",
        "    # Extract the ZIP file since the directory doesn't exist\n",
        "    # !unzip '/content/notebook_modules.zip' -d /content/\n",
        "    !unzip '/content/drive/MyDrive/Thesis_Data/CREMA_runs/import_notebook_modules/Win_10_step_5/notebook_modules.zip' -d /content/\n",
        "else:\n",
        "    print(\"Modules directory already exists. No need to extract the ZIP file.\")\n",
        "\n",
        "sys.path.append('/content/notebook_modules')\n",
        "\n",
        "import sequences\n",
        "import get_face_areas\n",
        "from get_models import load_weights_EE, load_weights_LSTM\n",
        "import run_functions\n",
        "\n",
        "multimodal_modules_directory = '/content/multimodal_modules'\n",
        "\n",
        "# Check if the expected directory or file exists\n",
        "if not os.path.exists(multimodal_modules_directory):\n",
        "    print(\"Multimodal modules directory does not exist, extracting the ZIP file...\")\n",
        "    # Extract the ZIP file since the directory doesn't exist\n",
        "    # !unzip '/content/notebook_modules.zip' -d /content/\n",
        "    !unzip '/content/drive/MyDrive/Thesis_Data/chinese/multimodal_modules.zip' -d /content/\n",
        "else:\n",
        "    print(\"Multimodal modules directory already exists. No need to extract the ZIP file.\")\n",
        "\n",
        "sys.path.append('/content/multimodal_modules')\n",
        "\n",
        "from audio_model import AudioModel\n",
        "from visual_model import VisualModel\n",
        "\n",
        "# Data folders\n",
        "video_data_folder = '/content/VideoMP4_testing'\n",
        "audio_data_folder = '/content/AudioWAV_resampled'\n",
        "\n",
        "# Extract zip folder on Google Drive and save it in Google Colab workspace\n",
        "if not os.path.exists(video_data_folder):\n",
        "    print(\"Video data folder does not exist, extracting the ZIP file...\")\n",
        "    # Extract the ZIP file since the directory doesn't exist\n",
        "    !unzip '/content/drive/MyDrive/Thesis_Data/chinese/video_files.zip' -d /content/\n",
        "else:\n",
        "    print(\"Video data folder already exists. No need to extract the ZIP file.\")\n",
        "\n",
        "if not os.path.exists(audio_data_folder):\n",
        "    print(\"Audio data folder does not exist, extracting the ZIP file...\")\n",
        "    # Extract the ZIP file since the directory doesn't exist\n",
        "    !unzip '/content/drive/MyDrive/Thesis_Data/chinese/audio_files.zip' -d /content/\n",
        "else:\n",
        "    print(\"Audio data folder already exists. No need to extract the ZIP file.\")\n",
        "\n",
        "def get_dataset(dataset, directory):\n",
        "    # Define the dataset and the directory\n",
        "    if dataset == \"CREMA-D\":\n",
        "        data = pd.read_csv(os.path.join(directory,r\"CREMA-D\\labels_testing.csv\"))\n",
        "        directory = os.path.join(directory,r\"CREMA-D\\audio_testing\")\n",
        "        my_encoding_dict_dataset = {'NEU': 0, 'ANG': 1, 'HAP': 2, 'SAD': 3}\n",
        "\n",
        "    elif dataset == \"CREMA-D-voted\":\n",
        "        data = pd.read_csv(os.path.join(directory,r\"CREMA-D\\labels_v_testing.csv\"))\n",
        "        directory = os.path.join(directory,r\"CREMA-D\\audio_v_testing\")\n",
        "        my_encoding_dict_dataset = {'N': 0, 'A': 1, 'H': 2, 'S': 3}\n",
        "\n",
        "    files = []\n",
        "\n",
        "    # Get a list of all files in the directory (audio files, change for video files)\n",
        "    for file in os.listdir(directory):\n",
        "        if file.endswith('.wav'):\n",
        "            files.append(file)\n",
        "\n",
        "    return files, data, directory, my_encoding_dict_dataset\n",
        "\n",
        "def get_crema_d_dataset(audio_directory, video_directory, labels_file, voted=True):\n",
        "    # Define the dataset and the directory\n",
        "    if voted:\n",
        "        # data = pd.read_csv(os.path.join(directory, labels_file))\n",
        "        # directory = os.path.join(directory,r\"CREMA-D\\audio_testing\")\n",
        "        my_encoding_dict_dataset = {'N': 0, 'A': 1, 'H': 2, 'S': 3}\n",
        "    else:\n",
        "        # data = pd.read_csv(os.path.join(directory,r\"CREMA-D\\labels_v_testing.csv\"))\n",
        "        # directory = os.path.join(directory,r\"CREMA-D\\audio_v_testing\")\n",
        "        my_encoding_dict_dataset = {'NEU': 0, 'ANG': 1, 'HAP': 2, 'SAD': 3}\n",
        "\n",
        "    audio_files = []\n",
        "    video_files = []\n",
        "\n",
        "    # Get a list of all files in the directory (audio files, change for video files)\n",
        "    for file in os.listdir(audio_directory):\n",
        "        if file.endswith('.wav'):\n",
        "            audio_files.append(file)\n",
        "\n",
        "    for file in os.listdir(video_directory):\n",
        "        if file.endswith('.mp4'):\n",
        "            video_files.append(file)\n",
        "\n",
        "    return audio_files, video_files, my_encoding_dict_dataset\n",
        "\n",
        "\n",
        "# Debugging function to check only one file\n",
        "def get_single_file(file):\n",
        "    # Get a single file for debugging\n",
        "    data = pd.read_csv(r\"C:\\Users\\DANIEL\\Desktop\\thesis\\CREMA-D\\labels_testing.csv\")\n",
        "    directory = r\"C:\\Users\\DANIEL\\Desktop\\thesis\\CREMA-D\\audio_testing\"\n",
        "    for row in data.iterrows():\n",
        "        if row[1]['File'] == file:\n",
        "            data = row[1]\n",
        "            break\n",
        "    my_encoding_dict_dataset = {'NEU': 0, 'ANG': 1, 'HAP': 2, 'SAD': 3}\n",
        "    return file, data, directory, my_encoding_dict_dataset\n",
        "\n",
        "def get_label_keys(data, my_encoding_dict_dataset):\n",
        "    # Get the label keys from the dataset\n",
        "    true_labels_multi = data['Emotion'] # Change this to the true labels of the multimodal model\n",
        "    true_labels_audio = data['Emotion'] # Change this to the true labels of the audio model\n",
        "    true_labels_visual = data['Emotion'] # Change this to the true labels of the visual model\n",
        "    label_keys_multi = true_labels_multi.map(my_encoding_dict_dataset).values\n",
        "    label_keys_audio = true_labels_audio.map(my_encoding_dict_dataset).values\n",
        "    label_keys_visual = true_labels_visual.map(my_encoding_dict_dataset).values\n",
        "\n",
        "    return label_keys_multi, true_labels_multi\n",
        "\n",
        "# Separete the audio and the video of the file\n",
        "def separate_audio_video(file):\n",
        "    # Separate the audio and video files\n",
        "\n",
        "    audio_directory = r\"C:\\Users\\DANIEL\\Desktop\\thesis\\CREMA-D\\AudioWav\"\n",
        "    video_directory = r\"C:\\Users\\DANIEL\\Desktop\\thesis\\CREMA-D\\VideoFlash\"\n",
        "\n",
        "    # Lood for audio file in AudioWav folder\n",
        "    audio_files = (os.path.join(audio_directory, file)+'.wav')\n",
        "\n",
        "    # Look for video file in VideoFlash folder\n",
        "    video_files = (os.path.join(video_directory, file)+'.flv')\n",
        "\n",
        "    return audio_files, video_files\n",
        "\n",
        "# Call both models to classify the audio and the video\n",
        "def save_results(results, name):\n",
        "    # Save the results for debugging as a csv file\n",
        "    results_df = pd.DataFrame(results)\n",
        "    # Get current directory\n",
        "    current_dir = os.getcwd()\n",
        "    results_save_path = os.path.join(current_dir, 'multimodal_results')\n",
        "    results_df.to_csv(os.path.join(results_save_path, f'{name}.csv'), index=False)\n",
        "    # results_df.to_csv(f'{name}.csv', index=False)\n",
        "\n",
        "def select_final_label(final_probabilities):\n",
        "    # Select the final label based on the combined probabilities\n",
        "    final_label = np.argmax(final_probabilities)\n",
        "    return final_label\n",
        "\n",
        "def combine_probabilities(audio_prob, video_prob, audio_weight=0.4, video_weight=0.6):\n",
        "    # Implement your logic to combine probabilities from both models\n",
        "    # print()\n",
        "    # print()\n",
        "    # print(\"-----------------Combining Probabilities-----------------\")\n",
        "    # print()\n",
        "    # print(\"Audio Probabilities: \", audio_prob)\n",
        "    audio_weighted = audio_prob*audio_weight\n",
        "    # print(\"Audio Prob. weighted: \", audio_weighted)\n",
        "    # print()\n",
        "    # print(\"Video Probabilities: \", video_prob)\n",
        "    video_weighted = video_prob*video_weight\n",
        "    # print(\"Video Prob. weighted: \", video_weighted)\n",
        "    combined_prob = audio_weighted + video_weighted\n",
        "    # print()\n",
        "    # print(\"Combined Probabilities: \", combined_prob)\n",
        "    return combined_prob\n",
        "\n",
        "def process_audio(audio_file):\n",
        "    audio_classifier = AudioModel()\n",
        "    out_prob, score, index, text_lab = audio_classifier.classify_audio_file(audio_file)\n",
        "    out_prob = out_prob.numpy()\n",
        "    # Add three zeros to match the dimensions of the visual model\n",
        "    out_prob = np.append(out_prob, [0, 0, 0]).reshape(1,7)\n",
        "    return out_prob, score, index, text_lab\n",
        "\n",
        "def process_video(video_file, backbone_model_path, LSTM_model_path):\n",
        "    video_classifier = VisualModel()\n",
        "    out_prob, score, index, text_lab = video_classifier.classify_video_file(video_file, backbone_model_path, LSTM_model_path)\n",
        "    out_prob = reorder_video_probabilities(out_prob)\n",
        "    return out_prob, score, index, text_lab\n",
        "\n",
        "def reorder_video_probabilities(video_probabilities):\n",
        "    # Reorder the video_probabilities to match the audio_probabilities\n",
        "    # Order = ['neu', 'ang', 'hap', 'sad']\n",
        "    # video_model = ['Neutral', 'Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger']\n",
        "    video_model_dict = {'neu' : 0, 'hap' : 1, 'sad' : 2, 'sur' : 3, 'fea' : 4, 'dis' : 5, 'ang' : 6}\n",
        "\n",
        "    new_probabilities = np.array([video_probabilities[video_model_dict['neu']],\n",
        "                                  video_probabilities[video_model_dict['ang']],\n",
        "                                  video_probabilities[video_model_dict['hap']],\n",
        "                                  video_probabilities[video_model_dict['sad']],\n",
        "                                  video_probabilities[video_model_dict['sur']],\n",
        "                                  video_probabilities[video_model_dict['fea']],\n",
        "                                  video_probabilities[video_model_dict['dis']]])\n",
        "\n",
        "    new_probabilities = new_probabilities.reshape(1,7)\n",
        "    # compare old and new probabilities\n",
        "    # print(\"Old Probabilities: \")\n",
        "    # print(video_probabilities)\n",
        "    # print(\"New Probabilities: \")\n",
        "    # print(new_probabilities)\n",
        "    return new_probabilities\n",
        "\n",
        "# Call both models to classify the audio and the video\n",
        "if __name__ == '__main__':\n",
        "    # Test runs are saved in Google Drive in folders named Run_1, Run_2, etc.\n",
        "    # Check the number of the latest run folder\n",
        "    run_folders = [folder for folder in os.listdir('/content/drive/MyDrive/Thesis_Data/chinese') if 'Run_' in folder]\n",
        "\n",
        "    continue_from_checkpoint = False\n",
        "    backbone_model_path = '/content/drive/MyDrive/Thesis_Data/CREMA_runs/Pretrained_models/Backbone_models/weights_0_66_37_wo_gl.h5'\n",
        "    LSTM_model_path = '/content/drive/MyDrive/Thesis_Data/CREMA_runs/Pretrained_models/LSTM_models/CREMA-D_with_config.h5'\n",
        "\n",
        "    # If run folders is empty, this is the first run\n",
        "    # Check if run folders is empty\n",
        "    if not run_folders:\n",
        "        this_run = 1\n",
        "        this_run_folder = f'/content/drive/MyDrive/Thesis_Data/chinese/Run_{this_run}'\n",
        "        os.makedirs(this_run_folder)\n",
        "        # Create subfolder for checkpoints\n",
        "        checkpoint_folder = os.path.join(this_run_folder, 'checkpoints')\n",
        "        os.makedirs(checkpoint_folder)\n",
        "    elif continue_from_checkpoint:\n",
        "        latest_run = max([int(folder.split('_')[1]) for folder in run_folders])\n",
        "        this_run = latest_run\n",
        "        this_run_folder = f'/content/drive/MyDrive/Thesis_Data/chinese/Run_{this_run}'\n",
        "        checkpoint_folder = os.path.join(this_run_folder, 'checkpoints')\n",
        "        checkpoint_files = [csv_file for csv_file in os.listdir(checkpoint_folder)]\n",
        "        last_checkpoint = max([int(checkpoint_file.split(\"_\")[-1].split(\".\")[0]) for checkpoint_file in checkpoint_files])\n",
        "        print(f\"Continuing from checkpoint {last_checkpoint}. (Run {this_run})\")\n",
        "    else:\n",
        "        latest_run = max([int(folder.split('_')[1]) for folder in run_folders])\n",
        "        this_run = latest_run + 1\n",
        "        this_run_folder = f'/content/drive/MyDrive/Thesis_Data/chinese/Run_{this_run}'\n",
        "        os.makedirs(this_run_folder)\n",
        "        # Create subfolder for checkpoints\n",
        "        checkpoint_folder = os.path.join(this_run_folder, 'checkpoints')\n",
        "        os.makedirs(checkpoint_folder)\n",
        "\n",
        "    # label_model = ['Neutral', 'Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger']\n",
        "    # my_encoding_dict_model = {'neu': 0, 'ang': 1, 'hap': 2, 'sad': 3} # Change this to include (or not) the extra classes of the visual model\n",
        "    my_encoding_dict_model = {'neu': 0, 'ang': 1, 'hap': 2, 'sad': 3, 'sur': 4, 'fea': 5, 'dis': 6}\n",
        "    label_names = ['neu', 'ang', 'hap', 'sad'] # Same as above\n",
        "\n",
        "    label_model_decoder = {0: 'Neutral', 1: 'Anger', 2: 'Happiness', 3: 'Sadness', 4: 'Surprise', 5: 'Fear', 6: 'Disgust'}\n",
        "\n",
        "    # dataset = \"CREMA-D\" # Change this to the dataset you are using\n",
        "    # directory = \"path_to_datasets\" # Change this to the directory where you save the datasets\n",
        "    # file = '1001_DFA_ANG_XX' # Change this to the file you want to classify\n",
        "    # file = '1001_IEO_SAD_MD'\n",
        "\n",
        "    # audio_folder = r\"C:\\MyDocs\\DTU\\MSc\\Thesis\\Data\\CREMA-D\\CREMA-D\\AudioWAV\"\n",
        "    # audio_folder = r\"C:\\_HomeDocs\\Ari\\DTU\\00-MSc\\Thesis\\Data\\AudioWAV_testing\"\n",
        "    # video_folder = r\"C:\\MyDocs\\DTU\\MSc\\Thesis\\Data\\CREMA-D\\CREMA-D\\VideoMP4\"\n",
        "    # video_folder = r\"C:\\_HomeDocs\\Ari\\DTU\\00-MSc\\Thesis\\Data\\VideoMP4_testing\"\n",
        "    audio_folder = audio_data_folder\n",
        "    video_folder = video_data_folder\n",
        "\n",
        "    # files, data, directory, my_encoding_dict_dataset = get_dataset(dataset, directory)\n",
        "    labels_data = pd.read_csv(r\"/content/drive/MyDrive/Thesis_Data/chinese/label_corrected_testing.csv\")\n",
        "    filenames = labels_data['filename'].tolist()\n",
        "    emotions_list = labels_data['Emotion'].tolist()\n",
        "    # labels_list = labels_data['Label'].tolist()\n",
        "    total_data_length = len(filenames)\n",
        "\n",
        "    # predictions_df = labels.copy()\n",
        "    # predictions_df['audio_prob'] = None\n",
        "    # predictions_df['video_prob'] = None\n",
        "\n",
        "    if continue_from_checkpoint:\n",
        "        filenames = filenames[last_checkpoint:]\n",
        "        emotions_list = emotions_list[last_checkpoint:]\n",
        "        progress = last_checkpoint + 1\n",
        "    else:\n",
        "        progress = 1\n",
        "\n",
        "    predictions_df = pd.DataFrame(columns=['filename', 'Emotion', 'audio_prob', 'video_prob', 'checkpoint'])\n",
        "    predictions_df['filename'] = filenames\n",
        "    predictions_df['Emotion'] = emotions_list\n",
        "    # predictions_df['Label'] = labels_list\n",
        "\n",
        "    # files, data, directory, my_encoding_dict_dataset = get_single_file(file)\n",
        "    # label_keys, true_labels = get_label_keys(data, my_encoding_dict_dataset)\n",
        "    # audio_input, video_input = separate_audio_video(file)\n",
        "    # debug_counter = 0\n",
        "    # audio_probs_list = []\n",
        "    # audio_probs_list = []\n",
        "    checkpoint_row = 1\n",
        "    # mp.set_start_method('spawn')\n",
        "    # with mp.Pool(2) as pool:\n",
        "    for file in filenames:\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(f\"Processing file {progress}/{total_data_length}\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        # if debug_counter>=4:\n",
        "            # break\n",
        "        audio_input = os.path.join(audio_folder, file + '.wav')\n",
        "        video_input = os.path.join(video_folder, file + '.mp4')\n",
        "        # audio_input = file\n",
        "        print(f'Audio Input: {audio_input}')\n",
        "        print(f'Video Input: {video_input}')\n",
        "        if file == \"1076_MTI_NEU_XX\":\n",
        "            print(\"Corrupted file. Skipping...\")\n",
        "            progress += 1\n",
        "            checkpoint_row += 1\n",
        "            continue\n",
        "        if file == \"1076_MTI_SAD_XX\":\n",
        "            print(\"Corrupted file. Skipping...\")\n",
        "            progress += 1\n",
        "            checkpoint_row += 1\n",
        "            continue\n",
        "\n",
        "        # audio_result = pool.apply_async(process_audio, (audio_input,))\n",
        "        # video_result = pool.apply_async(process_video, (video_input, backbone_model_path, LSTM_model_path))\n",
        "        audio_result = process_audio(audio_input)\n",
        "        video_result = process_video(video_input, backbone_model_path, LSTM_model_path)\n",
        "\n",
        "        # audio_probabilities, _, _, _ = audio_result.get()\n",
        "        # video_probabilities, _, _, _ = video_result.get()\n",
        "        audio_probabilities = audio_result[0]\n",
        "        video_probabilities = video_result[0]\n",
        "\n",
        "        # Save separate results for debugging\n",
        "        # save_results(audio_probabilities, 'audio_results')\n",
        "        # save_results(video_probabilities, 'video_results')\n",
        "\n",
        "        # print(\"We have now reordered the video probabilities\")\n",
        "        # print(video_probabilities.shape)\n",
        "        # print(video_probabilities)\n",
        "\n",
        "        # Combine results and determine final label\n",
        "        # final_probabilities = combine_probabilities(audio_probabilities, video_probabilities, audio_weight=0.5, video_weight=0.5)\n",
        "        # final_label = select_final_label(final_probabilities)\n",
        "        # final_label_name = label_model_decoder[final_label]\n",
        "\n",
        "        # print(f'Final Label: {final_label}', f'Final Probabilities: {final_probabilities}')\n",
        "        # print(f'Final Label Name: {final_label_name}')\n",
        "        # print(f'True Label: {true_labels}')\n",
        "        # audio_probs_list.append\n",
        "        # video_probs_list\n",
        "        # predictions_df.loc[predictions_df['filename'] == file, 'audio_prob'] = audio_probabilities\n",
        "        # predictions_df.loc[predictions_df['filename'] == file, 'video_prob'] = video_probabilities\n",
        "        predictions_df.at[predictions_df[predictions_df['filename'] == file].index[0], 'audio_prob'] = audio_probabilities\n",
        "        predictions_df.at[predictions_df[predictions_df['filename'] == file].index[0], 'video_prob'] = video_probabilities\n",
        "        predictions_df.at[predictions_df[predictions_df['filename'] == file].index[0], 'checkpoint'] = progress\n",
        "\n",
        "        # debug_counter += 1\n",
        "        if progress % 25 == 0:\n",
        "            # save the DataFrame to a csv file\n",
        "            checkpoint_data = predictions_df.head(checkpoint_row)\n",
        "            checkpoint_data.to_csv(os.path.join(checkpoint_folder,f'run_{this_run}_predicted_checkpoint_{progress}.csv'), index=False)\n",
        "            checkpoint_data.to_pickle(os.path.join(checkpoint_folder,f'run_{this_run}_predicted_checkpoint_{progress}.pkl'))\n",
        "            print(f\"Checkpoint {progress} saved.\")\n",
        "        progress += 1\n",
        "        checkpoint_row += 1\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print(\"------------------------------------------------------------------------------\")\n",
        "    # save the DataFrame to a csv file\n",
        "    predictions_df.to_csv(os.path.join(this_run_folder,f'run_{this_run}_predicted.csv'), index=False)\n",
        "    predictions_df.to_pickle(os.path.join(this_run_folder,f'run_{this_run}_predicted.pkl'))\n",
        "    predictions_df.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}