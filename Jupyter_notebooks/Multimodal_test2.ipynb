{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfW-hFwijFae",
        "outputId": "5b4bcfaa-ccc3-4002-8916-929506a75900"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keras_vggface is already installed with version 0.6\n",
            "keras_applications is already installed with version 1.0.8\n",
            "batch_face is already installed with version 1.4.0\n",
            "speechbrain is already installed with version 1.0.0\n",
            "Google Drive is already mounted.\n",
            "Modules directory already exists. No need to extract the ZIP file.\n",
            "Multimodal modules directory already exists. No need to extract the ZIP file.\n",
            "Video data folder already exists. No need to extract the ZIP file.\n",
            "Audio data folder already exists. No need to extract the ZIP file.\n",
            "Continuing from checkpoint 1440. (Run 2)\n",
            "-----------------------------------------------\n",
            "Processing file 1441/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1073_WSI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1073_WSI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1073_WSI_FEA_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1442/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_DFA_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_DFA_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_DFA_ANG_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1443/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_DFA_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_DFA_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_DFA_DIS_XX.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  30.0\n",
            "Video duration: 2.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1444/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_DFA_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_DFA_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_DFA_HAP_XX.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1445/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_DFA_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_DFA_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_DFA_NEU_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1446/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IEO_FEA_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IEO_FEA_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IEO_FEA_LO.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1447/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IEO_HAP_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IEO_HAP_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IEO_HAP_LO.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1448/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IEO_SAD_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IEO_SAD_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IEO_SAD_HI.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1449/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IEO_SAD_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IEO_SAD_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IEO_SAD_MD.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1450/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IOM_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IOM_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IOM_SAD_XX.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  30.0\n",
            "Video duration: 2.27 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1451/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_ITH_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_ITH_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_ITH_FEA_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1452/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_ITS_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_ITS_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_ITS_ANG_XX.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  30.0\n",
            "Video duration: 3.07 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1453/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_ITS_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_ITS_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_ITS_FEA_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1454/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_ITS_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_ITS_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_ITS_SAD_XX.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1455/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IWL_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IWL_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IWL_ANG_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1456/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IWL_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IWL_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IWL_DIS_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1457/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IWW_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IWW_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IWW_HAP_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1458/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_IWW_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_IWW_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_IWW_NEU_XX.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  30.0\n",
            "Video duration: 2.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1459/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_MTI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_MTI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_MTI_ANG_XX.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  30.0\n",
            "Video duration: 3.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1460/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_MTI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_MTI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_MTI_HAP_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1461/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_MTI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_MTI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_MTI_SAD_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1462/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_TAI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_TAI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_TAI_FEA_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1463/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_TIE_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_TIE_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_TIE_ANG_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1464/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_TIE_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_TIE_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_TIE_DIS_XX.mp4\n",
            "Number total of frames:  111\n",
            "FPS:  30.0\n",
            "Video duration: 3.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1465/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1074_WSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1074_WSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1074_WSI_ANG_XX.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  30.0\n",
            "Video duration: 2.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1466/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_DFA_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_DFA_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_DFA_SAD_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1467/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_IEO_DIS_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_IEO_DIS_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_IEO_DIS_HI.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1468/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_IEO_SAD_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_IEO_SAD_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_IEO_SAD_MD.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1469/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_IOM_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_IOM_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_IOM_DIS_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1470/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_IOM_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_IOM_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_IOM_HAP_XX.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  30.0\n",
            "Video duration: 1.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1471/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_ITS_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_ITS_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_ITS_DIS_XX.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  30.0\n",
            "Video duration: 3.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1472/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_ITS_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_ITS_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_ITS_SAD_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1473/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_IWL_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_IWL_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_IWL_HAP_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1474/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_IWL_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_IWL_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_IWL_SAD_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1475/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_MTI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_MTI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_MTI_SAD_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1476/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_TAI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_TAI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_TAI_ANG_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1477/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_TIE_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_TIE_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_TIE_DIS_XX.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  30.0\n",
            "Video duration: 3.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1478/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_TIE_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_TIE_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_TIE_SAD_XX.mp4\n",
            "Number total of frames:  104\n",
            "FPS:  30.0\n",
            "Video duration: 3.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1479/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_TSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_TSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_TSI_HAP_XX.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1480/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_TSI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_TSI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_TSI_SAD_XX.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  30.0\n",
            "Video duration: 2.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1481/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_WSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_WSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_WSI_ANG_XX.mp4\n",
            "Number total of frames:  107\n",
            "FPS:  30.0\n",
            "Video duration: 3.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1482/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1075_WSI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1075_WSI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1075_WSI_DIS_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1483/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_DFA_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_DFA_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_DFA_DIS_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1484/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_IEO_DIS_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_IEO_DIS_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_IEO_DIS_HI.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1485/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_IEO_FEA_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_IEO_FEA_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_IEO_FEA_HI.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  30.0\n",
            "Video duration: 1.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1486/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_IEO_FEA_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_IEO_FEA_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_IEO_FEA_MD.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  30.0\n",
            "Video duration: 2.07 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1487/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_IEO_SAD_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_IEO_SAD_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_IEO_SAD_HI.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1488/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_ITH_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_ITH_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_ITH_FEA_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1489/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_ITH_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_ITH_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_ITH_NEU_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1490/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_ITS_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_ITS_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_ITS_FEA_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1491/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_IWL_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_IWL_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_IWL_FEA_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1492/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_IWW_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_IWW_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_IWW_ANG_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1493/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_MTI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_MTI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_MTI_FEA_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1494/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_MTI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_MTI_NEU_XX.mp4\n",
            "Corrupted file. Skipping...\n",
            "-----------------------------------------------\n",
            "Processing file 1495/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_MTI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_MTI_SAD_XX.mp4\n",
            "Corrupted file. Skipping...\n",
            "-----------------------------------------------\n",
            "Processing file 1496/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_TAI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_TAI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_TAI_ANG_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1497/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_TAI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_TAI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_TAI_FEA_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1498/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_TAI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_TAI_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_TAI_NEU_XX.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  30.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1499/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1076_TIE_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1076_TIE_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1076_TIE_SAD_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1500/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_IEO_ANG_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_IEO_ANG_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_IEO_ANG_HI.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1501/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_IEO_ANG_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_IEO_ANG_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_IEO_ANG_MD.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  30.0\n",
            "Video duration: 1.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1502/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_IEO_DIS_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_IEO_DIS_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_IEO_DIS_MD.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  30.0\n",
            "Video duration: 1.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1503/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_ITH_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_ITH_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_ITH_DIS_XX.mp4\n",
            "Number total of frames:  110\n",
            "FPS:  30.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1504/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_ITS_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_ITS_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_ITS_HAP_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1505/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_IWL_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_IWL_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_IWL_ANG_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1506/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_IWL_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_IWL_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_IWL_FEA_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1507/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_IWL_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_IWL_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_IWL_HAP_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1508/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_IWW_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_IWW_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_IWW_ANG_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1509/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_IWW_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_IWW_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_IWW_HAP_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1510/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_MTI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_MTI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_MTI_DIS_XX.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  30.0\n",
            "Video duration: 2.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1511/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_MTI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_MTI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_MTI_SAD_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1512/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_TAI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_TAI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_TAI_ANG_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1513/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_TAI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_TAI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_TAI_HAP_XX.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  30.0\n",
            "Video duration: 2.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1514/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_TAI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_TAI_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_TAI_NEU_XX.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  30.0\n",
            "Video duration: 2.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1515/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_TIE_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_TIE_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_TIE_ANG_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1516/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_TIE_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_TIE_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_TIE_FEA_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1517/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_TIE_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_TIE_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_TIE_HAP_XX.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  30.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1518/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_TIE_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_TIE_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_TIE_SAD_XX.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  30.0\n",
            "Video duration: 3.07 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1519/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_TSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_TSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_TSI_HAP_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1520/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1077_WSI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1077_WSI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1077_WSI_FEA_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1521/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_DFA_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_DFA_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_DFA_ANG_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1522/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_DFA_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_DFA_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_DFA_DIS_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1523/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_DFA_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_DFA_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_DFA_NEU_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1524/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_IEO_HAP_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_IEO_HAP_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_IEO_HAP_LO.mp4\n",
            "Number total of frames:  45\n",
            "FPS:  30.0\n",
            "Video duration: 1.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1525/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_IEO_SAD_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_IEO_SAD_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_IEO_SAD_HI.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  30.0\n",
            "Video duration: 2.27 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1526/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_IEO_SAD_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_IEO_SAD_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_IEO_SAD_LO.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  30.0\n",
            "Video duration: 1.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1527/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_ITH_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_ITH_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_ITH_ANG_XX.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1528/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_ITH_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_ITH_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_ITH_HAP_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1529/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_ITS_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_ITS_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_ITS_ANG_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1530/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_ITS_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_ITS_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_ITS_DIS_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1531/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_TAI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_TAI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_TAI_HAP_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1532/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_TIE_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_TIE_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_TIE_ANG_XX.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  30.0\n",
            "Video duration: 2.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1533/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_TIE_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_TIE_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_TIE_FEA_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1534/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_TSI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_TSI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_TSI_SAD_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1535/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1078_WSI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1078_WSI_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1078_WSI_NEU_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1536/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_DFA_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_DFA_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_DFA_DIS_XX.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  30.0\n",
            "Video duration: 2.27 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1537/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IEO_ANG_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IEO_ANG_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IEO_ANG_LO.mp4\n",
            "Number total of frames:  48\n",
            "FPS:  30.0\n",
            "Video duration: 1.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1538/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IEO_DIS_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IEO_DIS_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IEO_DIS_LO.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1539/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IEO_HAP_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IEO_HAP_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IEO_HAP_MD.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1540/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IEO_SAD_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IEO_SAD_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IEO_SAD_LO.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1541/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IOM_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IOM_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IOM_ANG_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1542/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IOM_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IOM_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IOM_FEA_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1543/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IOM_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IOM_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IOM_NEU_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1544/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IOM_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IOM_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IOM_SAD_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1545/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_ITH_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_ITH_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_ITH_ANG_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1546/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_ITH_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_ITH_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_ITH_SAD_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1547/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IWL_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IWL_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IWL_ANG_XX.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1548/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IWL_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IWL_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IWL_DIS_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1549/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IWL_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IWL_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IWL_HAP_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1550/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_IWW_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_IWW_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_IWW_FEA_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1551/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_MTI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_MTI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_MTI_HAP_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1552/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_TAI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_TAI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_TAI_ANG_XX.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  30.0\n",
            "Video duration: 2.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1553/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_TIE_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_TIE_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_TIE_HAP_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1554/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_TSI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_TSI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_TSI_FEA_XX.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  30.0\n",
            "Video duration: 2.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1555/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_TSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_TSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_TSI_HAP_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1556/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_TSI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_TSI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_TSI_SAD_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1557/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_WSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_WSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_WSI_HAP_XX.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1558/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1079_WSI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1079_WSI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1079_WSI_SAD_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1559/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_DFA_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_DFA_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_DFA_SAD_XX.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1560/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_IEO_DIS_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_IEO_DIS_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_IEO_DIS_MD.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1561/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_IEO_HAP_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_IEO_HAP_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_IEO_HAP_LO.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1562/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_IEO_SAD_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_IEO_SAD_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_IEO_SAD_HI.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1563/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_IOM_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_IOM_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_IOM_DIS_XX.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  30.0\n",
            "Video duration: 3.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1564/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_ITH_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_ITH_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_ITH_DIS_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1565/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_ITS_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_ITS_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_ITS_ANG_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1566/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_ITS_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_ITS_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_ITS_DIS_XX.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  30.0\n",
            "Video duration: 3.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1567/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_ITS_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_ITS_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_ITS_HAP_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1568/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_ITS_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_ITS_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_ITS_SAD_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1569/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_IWL_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_IWL_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_IWL_SAD_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1570/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_MTI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_MTI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_MTI_FEA_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1571/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_MTI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_MTI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_MTI_HAP_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1572/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_MTI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_MTI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_MTI_SAD_XX.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  30.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1573/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_TIE_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_TIE_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_TIE_ANG_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1574/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_TIE_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_TIE_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_TIE_SAD_XX.mp4\n",
            "Number total of frames:  119\n",
            "FPS:  30.0\n",
            "Video duration: 3.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1575/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_TSI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_TSI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_TSI_DIS_XX.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1576/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_TSI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_TSI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_TSI_FEA_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1577/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_TSI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_TSI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_TSI_SAD_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1578/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_WSI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_WSI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_WSI_DIS_XX.mp4\n",
            "Number total of frames:  108\n",
            "FPS:  30.0\n",
            "Video duration: 3.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1579/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1080_WSI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1080_WSI_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1080_WSI_NEU_XX.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  30.0\n",
            "Video duration: 3.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1580/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_DFA_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_DFA_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_DFA_HAP_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1581/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IEO_DIS_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IEO_DIS_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IEO_DIS_MD.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1582/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IEO_HAP_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IEO_HAP_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IEO_HAP_LO.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1583/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IEO_HAP_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IEO_HAP_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IEO_HAP_MD.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1584/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IEO_SAD_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IEO_SAD_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IEO_SAD_LO.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1585/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IOM_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IOM_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IOM_ANG_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1586/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IOM_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IOM_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IOM_FEA_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1587/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IOM_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IOM_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IOM_HAP_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1588/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IOM_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IOM_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IOM_NEU_XX.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  30.0\n",
            "Video duration: 1.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1589/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IWL_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IWL_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IWL_NEU_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1590/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_IWW_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_IWW_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_IWW_SAD_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1591/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_MTI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_MTI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_MTI_ANG_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1592/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_TAI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_TAI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_TAI_SAD_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1593/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_TIE_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_TIE_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_TIE_DIS_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1594/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_TIE_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_TIE_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_TIE_FEA_XX.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  30.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1595/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1081_WSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1081_WSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1081_WSI_HAP_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1596/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_DFA_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_DFA_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_DFA_FEA_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1597/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_DFA_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_DFA_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_DFA_SAD_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1598/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IEO_ANG_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IEO_ANG_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IEO_ANG_HI.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1599/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IEO_HAP_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IEO_HAP_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IEO_HAP_MD.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  30.0\n",
            "Video duration: 1.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1600/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IEO_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IEO_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IEO_NEU_XX.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  30.0\n",
            "Video duration: 1.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1601/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IEO_SAD_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IEO_SAD_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IEO_SAD_LO.mp4\n",
            "Number total of frames:  57\n",
            "FPS:  30.0\n",
            "Video duration: 1.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1602/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IEO_SAD_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IEO_SAD_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IEO_SAD_MD.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  30.0\n",
            "Video duration: 2.27 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1603/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IOM_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IOM_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IOM_SAD_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1604/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_ITH_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_ITH_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_ITH_DIS_XX.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  30.0\n",
            "Video duration: 2.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1605/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_ITH_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_ITH_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_ITH_FEA_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1606/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_ITH_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_ITH_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_ITH_HAP_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1607/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_ITH_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_ITH_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_ITH_NEU_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1608/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_ITS_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_ITS_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_ITS_DIS_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1609/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IWL_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IWL_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IWL_ANG_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1610/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IWW_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IWW_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IWW_DIS_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1611/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_IWW_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_IWW_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_IWW_FEA_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1612/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_MTI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_MTI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_MTI_FEA_XX.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  30.0\n",
            "Video duration: 2.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1613/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_TAI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_TAI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_TAI_ANG_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1614/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_TAI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_TAI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_TAI_DIS_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1615/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_TAI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_TAI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_TAI_HAP_XX.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  30.0\n",
            "Video duration: 2.07 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1616/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_TIE_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_TIE_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_TIE_DIS_XX.mp4\n",
            "Number total of frames:  111\n",
            "FPS:  30.0\n",
            "Video duration: 3.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1617/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_TSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_TSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_TSI_ANG_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1618/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_TSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_TSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_TSI_HAP_XX.mp4\n",
            "Number total of frames:  48\n",
            "FPS:  30.0\n",
            "Video duration: 1.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1619/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1082_WSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1082_WSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1082_WSI_HAP_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1620/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_DFA_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_DFA_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_DFA_ANG_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "Checkpoint 1620 saved.\n",
            "-----------------------------------------------\n",
            "Processing file 1621/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_DFA_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_DFA_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_DFA_FEA_XX.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  30.0\n",
            "Video duration: 2.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1622/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IEO_ANG_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IEO_ANG_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IEO_ANG_MD.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1623/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IEO_HAP_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IEO_HAP_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IEO_HAP_LO.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  30.0\n",
            "Video duration: 1.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1624/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IEO_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IEO_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IEO_NEU_XX.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1625/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IEO_SAD_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IEO_SAD_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IEO_SAD_MD.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1626/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IOM_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IOM_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IOM_SAD_XX.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  30.0\n",
            "Video duration: 2.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1627/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_ITH_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_ITH_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_ITH_ANG_XX.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  30.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1628/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_ITH_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_ITH_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_ITH_DIS_XX.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  30.0\n",
            "Video duration: 2.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1629/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_ITS_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_ITS_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_ITS_FEA_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1630/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_ITS_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_ITS_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_ITS_HAP_XX.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  30.0\n",
            "Video duration: 2.27 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1631/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_ITS_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_ITS_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_ITS_SAD_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1632/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IWL_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IWL_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IWL_DIS_XX.mp4\n",
            "Number total of frames:  131\n",
            "FPS:  30.0\n",
            "Video duration: 4.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1633/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IWL_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IWL_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IWL_SAD_XX.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1634/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IWW_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IWW_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IWW_ANG_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1635/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IWW_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IWW_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IWW_DIS_XX.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1636/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_IWW_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_IWW_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_IWW_NEU_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1637/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_MTI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_MTI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_MTI_DIS_XX.mp4\n",
            "Number total of frames:  126\n",
            "FPS:  30.0\n",
            "Video duration: 4.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1638/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_MTI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_MTI_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_MTI_NEU_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1639/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_TAI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_TAI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_TAI_DIS_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1640/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_TIE_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_TIE_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_TIE_FEA_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1641/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_TSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_TSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_TSI_ANG_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1642/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_TSI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_TSI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_TSI_FEA_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1643/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_TSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_TSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_TSI_HAP_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1644/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_WSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_WSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_WSI_ANG_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1645/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_WSI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_WSI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_WSI_DIS_XX.mp4\n",
            "Number total of frames:  122\n",
            "FPS:  30.0\n",
            "Video duration: 4.07 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1646/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_WSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_WSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_WSI_HAP_XX.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  30.0\n",
            "Video duration: 2.27 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1647/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1083_WSI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1083_WSI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1083_WSI_SAD_XX.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1648/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IEO_ANG_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IEO_ANG_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IEO_ANG_LO.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1649/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IEO_FEA_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IEO_FEA_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IEO_FEA_HI.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1650/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IEO_FEA_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IEO_FEA_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IEO_FEA_LO.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1651/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IEO_FEA_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IEO_FEA_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IEO_FEA_MD.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1652/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IOM_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IOM_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IOM_FEA_XX.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  30.0\n",
            "Video duration: 3.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1653/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IOM_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IOM_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IOM_HAP_XX.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  30.0\n",
            "Video duration: 2.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1654/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_ITH_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_ITH_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_ITH_DIS_XX.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1655/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_ITS_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_ITS_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_ITS_DIS_XX.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1656/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_ITS_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_ITS_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_ITS_NEU_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1657/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IWL_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IWL_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IWL_FEA_XX.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  30.0\n",
            "Video duration: 3.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1658/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IWL_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IWL_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IWL_HAP_XX.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  30.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1659/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_IWL_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_IWL_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_IWL_SAD_XX.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  30.0\n",
            "Video duration: 3.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1660/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_MTI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_MTI_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_MTI_NEU_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1661/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_TAI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_TAI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_TAI_SAD_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1662/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_TIE_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_TIE_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_TIE_NEU_XX.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  30.0\n",
            "Video duration: 2.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1663/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_TSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_TSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_TSI_HAP_XX.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  30.0\n",
            "Video duration: 3.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1664/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_WSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_WSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_WSI_ANG_XX.mp4\n",
            "Number total of frames:  110\n",
            "FPS:  30.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1665/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1084_WSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1084_WSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1084_WSI_HAP_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1666/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_DFA_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_DFA_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_DFA_DIS_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1667/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IEO_ANG_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IEO_ANG_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IEO_ANG_LO.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  30.0\n",
            "Video duration: 2.07 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1668/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IEO_DIS_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IEO_DIS_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IEO_DIS_HI.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1669/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IEO_HAP_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IEO_HAP_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IEO_HAP_HI.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1670/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IEO_HAP_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IEO_HAP_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IEO_HAP_MD.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1671/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IEO_SAD_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IEO_SAD_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IEO_SAD_MD.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1672/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IOM_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IOM_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IOM_HAP_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1673/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_ITH_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_ITH_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_ITH_SAD_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1674/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_ITS_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_ITS_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_ITS_DIS_XX.mp4\n",
            "Number total of frames:  110\n",
            "FPS:  30.0\n",
            "Video duration: 3.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1675/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IWL_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IWL_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IWL_ANG_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1676/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IWL_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IWL_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IWL_HAP_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1677/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_IWW_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_IWW_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_IWW_HAP_XX.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1678/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_MTI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_MTI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_MTI_FEA_XX.mp4\n",
            "Number total of frames:  107\n",
            "FPS:  30.0\n",
            "Video duration: 3.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1679/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_TAI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_TAI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_TAI_HAP_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1680/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_TAI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_TAI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_TAI_SAD_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1681/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_TIE_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_TIE_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_TIE_DIS_XX.mp4\n",
            "Number total of frames:  116\n",
            "FPS:  30.0\n",
            "Video duration: 3.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1682/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_TIE_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_TIE_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_TIE_HAP_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1683/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_TSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_TSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_TSI_ANG_XX.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  30.0\n",
            "Video duration: 2.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1684/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_WSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_WSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_WSI_ANG_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1685/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_WSI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_WSI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_WSI_DIS_XX.mp4\n",
            "Number total of frames:  114\n",
            "FPS:  30.0\n",
            "Video duration: 3.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1686/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1085_WSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1085_WSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1085_WSI_HAP_XX.mp4\n",
            "Number total of frames:  74\n",
            "FPS:  30.0\n",
            "Video duration: 2.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1687/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_DFA_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_DFA_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_DFA_DIS_XX.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  30.0\n",
            "Video duration: 1.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1688/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_DFA_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_DFA_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_DFA_SAD_XX.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1689/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IEO_ANG_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IEO_ANG_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IEO_ANG_LO.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1690/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IEO_ANG_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IEO_ANG_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IEO_ANG_MD.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1691/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IEO_FEA_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IEO_FEA_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IEO_FEA_LO.mp4\n",
            "Number total of frames:  51\n",
            "FPS:  30.0\n",
            "Video duration: 1.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1692/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IEO_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IEO_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IEO_NEU_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1693/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IEO_SAD_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IEO_SAD_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IEO_SAD_HI.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1694/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IOM_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IOM_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IOM_ANG_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1695/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IOM_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IOM_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IOM_HAP_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1696/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_ITH_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_ITH_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_ITH_DIS_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1697/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_ITH_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_ITH_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_ITH_HAP_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1698/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_ITH_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_ITH_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_ITH_NEU_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1699/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_ITS_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_ITS_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_ITS_DIS_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1700/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_ITS_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_ITS_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_ITS_FEA_XX.mp4\n",
            "Number total of frames:  68\n",
            "FPS:  30.0\n",
            "Video duration: 2.27 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1701/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_ITS_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_ITS_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_ITS_HAP_XX.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  30.0\n",
            "Video duration: 2.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1702/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IWL_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IWL_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IWL_FEA_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1703/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IWL_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IWL_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IWL_HAP_XX.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  30.0\n",
            "Video duration: 1.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1704/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_IWL_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_IWL_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_IWL_SAD_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1705/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_MTI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_MTI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_MTI_FEA_XX.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1706/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_MTI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_MTI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_MTI_HAP_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1707/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_TAI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_TAI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_TAI_DIS_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1708/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_TAI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_TAI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_TAI_FEA_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1709/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_TAI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_TAI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_TAI_SAD_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1710/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_TIE_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_TIE_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_TIE_ANG_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1711/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_TIE_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_TIE_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_TIE_DIS_XX.mp4\n",
            "Number total of frames:  102\n",
            "FPS:  30.0\n",
            "Video duration: 3.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1712/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_TSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_TSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_TSI_HAP_XX.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1713/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1086_WSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1086_WSI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1086_WSI_ANG_XX.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  30.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1714/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_DFA_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_DFA_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_DFA_HAP_XX.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1715/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_IEO_DIS_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_IEO_DIS_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_IEO_DIS_MD.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1716/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_IEO_FEA_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_IEO_FEA_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_IEO_FEA_HI.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1717/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_IEO_SAD_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_IEO_SAD_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_IEO_SAD_MD.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  30.0\n",
            "Video duration: 2.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1718/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_IOM_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_IOM_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_IOM_HAP_XX.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  30.0\n",
            "Video duration: 1.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1719/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_ITH_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_ITH_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_ITH_FEA_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1720/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_ITS_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_ITS_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_ITS_SAD_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1721/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_IWL_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_IWL_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_IWL_DIS_XX.mp4\n",
            "Number total of frames:  99\n",
            "FPS:  30.0\n",
            "Video duration: 3.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1722/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_IWL_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_IWL_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_IWL_SAD_XX.mp4\n",
            "Number total of frames:  80\n",
            "FPS:  30.0\n",
            "Video duration: 2.67 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1723/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_IWW_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_IWW_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_IWW_FEA_XX.mp4\n",
            "Number total of frames:  53\n",
            "FPS:  30.0\n",
            "Video duration: 1.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1724/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_MTI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_MTI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_MTI_SAD_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1725/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_TAI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_TAI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_TAI_ANG_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1726/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_TAI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_TAI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_TAI_DIS_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1727/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_TIE_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_TIE_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_TIE_HAP_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1728/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_TSI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_TSI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_TSI_FEA_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1729/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1087_WSI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1087_WSI_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1087_WSI_HAP_XX.mp4\n",
            "Number total of frames:  59\n",
            "FPS:  30.0\n",
            "Video duration: 1.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1730/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_DFA_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_DFA_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_DFA_ANG_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1731/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_DFA_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_DFA_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_DFA_HAP_XX.mp4\n",
            "Number total of frames:  63\n",
            "FPS:  30.0\n",
            "Video duration: 2.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1732/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_DFA_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_DFA_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_DFA_NEU_XX.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  30.0\n",
            "Video duration: 2.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1733/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_IEO_ANG_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_IEO_ANG_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_IEO_ANG_MD.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1734/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_IEO_DIS_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_IEO_DIS_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_IEO_DIS_MD.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1735/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_IEO_SAD_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_IEO_SAD_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_IEO_SAD_HI.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1736/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_IOM_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_IOM_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_IOM_ANG_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1737/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_IOM_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_IOM_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_IOM_NEU_XX.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  30.0\n",
            "Video duration: 1.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1738/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_ITS_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_ITS_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_ITS_ANG_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1739/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_ITS_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_ITS_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_ITS_FEA_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1740/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_IWL_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_IWL_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_IWL_DIS_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1741/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_IWL_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_IWL_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_IWL_SAD_XX.mp4\n",
            "Number total of frames:  93\n",
            "FPS:  30.0\n",
            "Video duration: 3.1 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1742/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_TAI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_TAI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_TAI_DIS_XX.mp4\n",
            "Number total of frames:  87\n",
            "FPS:  30.0\n",
            "Video duration: 2.9 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1743/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_TIE_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_TIE_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_TIE_HAP_XX.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1744/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_TIE_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_TIE_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_TIE_SAD_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1745/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1088_TSI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1088_TSI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1088_TSI_DIS_XX.mp4\n",
            "Number total of frames:  72\n",
            "FPS:  30.0\n",
            "Video duration: 2.4 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1746/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IEO_ANG_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IEO_ANG_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IEO_ANG_HI.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1747/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IEO_DIS_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IEO_DIS_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IEO_DIS_LO.mp4\n",
            "Number total of frames:  83\n",
            "FPS:  30.0\n",
            "Video duration: 2.77 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1748/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IEO_HAP_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IEO_HAP_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IEO_HAP_HI.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1749/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IEO_SAD_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IEO_SAD_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IEO_SAD_LO.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1750/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IOM_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IOM_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IOM_FEA_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1751/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IOM_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IOM_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IOM_SAD_XX.mp4\n",
            "Number total of frames:  62\n",
            "FPS:  30.0\n",
            "Video duration: 2.07 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1752/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_ITH_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_ITH_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_ITH_HAP_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1753/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_ITS_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_ITS_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_ITS_FEA_XX.mp4\n",
            "Number total of frames:  95\n",
            "FPS:  30.0\n",
            "Video duration: 3.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1754/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_ITS_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_ITS_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_ITS_SAD_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1755/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IWL_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IWL_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IWL_ANG_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1756/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IWL_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IWL_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IWL_FEA_XX.mp4\n",
            "Number total of frames:  84\n",
            "FPS:  30.0\n",
            "Video duration: 2.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1757/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IWL_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IWL_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IWL_SAD_XX.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  30.0\n",
            "Video duration: 2.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1758/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_IWW_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_IWW_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_IWW_FEA_XX.mp4\n",
            "Number total of frames:  77\n",
            "FPS:  30.0\n",
            "Video duration: 2.57 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1759/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_TAI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_TAI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_TAI_DIS_XX.mp4\n",
            "Number total of frames:  111\n",
            "FPS:  30.0\n",
            "Video duration: 3.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1760/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_TIE_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_TIE_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_TIE_ANG_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1761/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_TIE_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_TIE_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_TIE_SAD_XX.mp4\n",
            "Number total of frames:  96\n",
            "FPS:  30.0\n",
            "Video duration: 3.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1762/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_TSI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_TSI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_TSI_DIS_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1763/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_TSI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_TSI_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_TSI_FEA_XX.mp4\n",
            "Number total of frames:  56\n",
            "FPS:  30.0\n",
            "Video duration: 1.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1764/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1089_WSI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1089_WSI_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1089_WSI_NEU_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1765/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_DFA_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_DFA_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_DFA_FEA_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1766/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_IEO_SAD_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_IEO_SAD_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_IEO_SAD_HI.mp4\n",
            "Number total of frames:  54\n",
            "FPS:  30.0\n",
            "Video duration: 1.8 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1767/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_IOM_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_IOM_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_IOM_ANG_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1768/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_ITH_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_ITH_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_ITH_FEA_XX.mp4\n",
            "Number total of frames:  104\n",
            "FPS:  30.0\n",
            "Video duration: 3.47 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1769/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_ITH_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_ITH_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_ITH_HAP_XX.mp4\n",
            "Number total of frames:  65\n",
            "FPS:  30.0\n",
            "Video duration: 2.17 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1770/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_IWL_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_IWL_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_IWL_HAP_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1771/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_IWW_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_IWW_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_IWW_DIS_XX.mp4\n",
            "Number total of frames:  69\n",
            "FPS:  30.0\n",
            "Video duration: 2.3 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1772/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_MTI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_MTI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_MTI_ANG_XX.mp4\n",
            "Number total of frames:  101\n",
            "FPS:  30.0\n",
            "Video duration: 3.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1773/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_TAI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_TAI_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_TAI_DIS_XX.mp4\n",
            "Number total of frames:  92\n",
            "FPS:  30.0\n",
            "Video duration: 3.07 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1774/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_TAI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_TAI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_TAI_SAD_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1775/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_TIE_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_TIE_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_TIE_ANG_XX.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  30.0\n",
            "Video duration: 2.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1776/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_TIE_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_TIE_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_TIE_FEA_XX.mp4\n",
            "Number total of frames:  89\n",
            "FPS:  30.0\n",
            "Video duration: 2.97 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1777/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_TIE_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_TIE_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_TIE_HAP_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1778/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1090_TSI_SAD_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1090_TSI_SAD_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1090_TSI_SAD_XX.mp4\n",
            "Number total of frames:  78\n",
            "FPS:  30.0\n",
            "Video duration: 2.6 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1779/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IEO_ANG_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IEO_ANG_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IEO_ANG_HI.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1780/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IEO_ANG_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IEO_ANG_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IEO_ANG_LO.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1781/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IEO_DIS_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IEO_DIS_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IEO_DIS_MD.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1782/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IEO_HAP_HI.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IEO_HAP_HI.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IEO_HAP_HI.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1783/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IEO_SAD_LO.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IEO_SAD_LO.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IEO_SAD_LO.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1784/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IEO_SAD_MD.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IEO_SAD_MD.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IEO_SAD_MD.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1785/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IOM_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IOM_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IOM_ANG_XX.mp4\n",
            "Number total of frames:  60\n",
            "FPS:  30.0\n",
            "Video duration: 2.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1786/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IOM_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IOM_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IOM_DIS_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1787/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IOM_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IOM_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IOM_HAP_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1788/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_ITH_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_ITH_NEU_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_ITH_NEU_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1789/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_ITS_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_ITS_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_ITS_ANG_XX.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  30.0\n",
            "Video duration: 2.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1790/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_ITS_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_ITS_DIS_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_ITS_DIS_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1791/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_ITS_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_ITS_HAP_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_ITS_HAP_XX.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  30.0\n",
            "Video duration: 2.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1792/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_IWL_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_IWL_FEA_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name video:  1091_IWL_FEA_XX.mp4\n",
            "Number total of frames:  81\n",
            "FPS:  30.0\n",
            "Video duration: 2.7 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1793/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_MTI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_MTI_ANG_XX.mp4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  1091_MTI_ANG_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1794/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_MTI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_MTI_DIS_XX.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  1091_MTI_DIS_XX.mp4\n",
            "Number total of frames:  90\n",
            "FPS:  30.0\n",
            "Video duration: 3.0 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1795/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_MTI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_MTI_HAP_XX.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  1091_MTI_HAP_XX.mp4\n",
            "Number total of frames:  86\n",
            "FPS:  30.0\n",
            "Video duration: 2.87 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1796/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_MTI_NEU_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_MTI_NEU_XX.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  1091_MTI_NEU_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1797/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_TAI_FEA_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_TAI_FEA_XX.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  1091_TAI_FEA_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1798/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_TAI_HAP_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_TAI_HAP_XX.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  1091_TAI_HAP_XX.mp4\n",
            "Number total of frames:  71\n",
            "FPS:  30.0\n",
            "Video duration: 2.37 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1799/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_TSI_ANG_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_TSI_ANG_XX.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  1091_TSI_ANG_XX.mp4\n",
            "Number total of frames:  66\n",
            "FPS:  30.0\n",
            "Video duration: 2.2 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "-----------------------------------------------\n",
            "Processing file 1800/1800\n",
            "-----------------------------------------------\n",
            "Audio Input: /content/AudioWAV_multimodal/1091_WSI_DIS_XX.wav\n",
            "Video Input: /content/VideoMP4_multimodal/1091_WSI_DIS_XX.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:speechbrain.lobes.models.huggingface_transformers.huggingface:speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name video:  1091_WSI_DIS_XX.mp4\n",
            "Number total of frames:  75\n",
            "FPS:  30.0\n",
            "Video duration: 2.5 s\n",
            "Frame width: 480\n",
            "Frame height: 360\n",
            "Checkpoint 1800 saved.\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pkg_resources\n",
        "# Install packages\n",
        "package_names = ['keras_vggface', 'keras_applications', 'batch_face', 'speechbrain']\n",
        "for package_name in package_names:\n",
        "  try:\n",
        "    dist = pkg_resources.get_distribution(package_name)\n",
        "    print(f\"{package_name} is already installed with version {dist.version}\")\n",
        "  except pkg_resources.DistributionNotFound:\n",
        "    print(f\"{package_name} is not installed, installing now...\")\n",
        "    !pip install {package_name}\n",
        "\n",
        "# !pip install --upgrade --force-reinstall keras_vggface\n",
        "# !pip install keras_vggface\n",
        "# !pip install keras_applications\n",
        "# !pip install batch_face\n",
        "\n",
        "# Fix package files\n",
        "!sed -i 's/from keras.utils import layer_utils/from tensorflow.python.keras.utils import layer_utils/' /usr/local/lib/python3.10/dist-packages/keras_vggface/models.py\n",
        "!sed -i 's/from keras.utils.data_utils import get_file/from tensorflow.python.keras.utils.data_utils import get_file/' /usr/local/lib/python3.10/dist-packages/keras_vggface/models.py\n",
        "!sed -i 's/from keras.utils.data_utils import get_file/from tensorflow.python.keras.utils.data_utils import get_file/' /usr/local/lib/python3.10/dist-packages/keras_vggface/utils.py\n",
        "!sed -i 's/from keras.engine.topology import get_source_inputs/from tensorflow.python.keras.utils.layer_utils import get_source_inputs/' /usr/local/lib/python3.10/dist-packages/keras_vggface/models.py\n",
        "\n",
        "# import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from scipy import stats\n",
        "import pickle\n",
        "import sys\n",
        "# import speechbrain\n",
        "import multiprocessing as mp\n",
        "# from select_video_subset import select_video_subset\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category = FutureWarning)\n",
        "\n",
        "# Mount drive\n",
        "from google.colab import drive\n",
        "\n",
        "def is_drive_mounted():\n",
        "    drive_path = '/content/drive'\n",
        "    return os.path.isdir(drive_path) and os.listdir(drive_path)\n",
        "\n",
        "# Mount Google Drive if it is not already mounted\n",
        "if not is_drive_mounted():\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive is mounted now!\")\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")\n",
        "\n",
        "expected_directory = '/content/notebook_modules'\n",
        "\n",
        "# Check if the expected directory or file exists\n",
        "if not os.path.exists(expected_directory):\n",
        "    print(\"Modules directory does not exist, extracting the ZIP file...\")\n",
        "    # Extract the ZIP file since the directory doesn't exist\n",
        "    # !unzip '/content/notebook_modules.zip' -d /content/\n",
        "    !unzip '/content/drive/MyDrive/Thesis_Data/CREMA_runs/import_notebook_modules/Win_10_step_5/notebook_modules.zip' -d /content/\n",
        "else:\n",
        "    print(\"Modules directory already exists. No need to extract the ZIP file.\")\n",
        "\n",
        "sys.path.append('/content/notebook_modules')\n",
        "\n",
        "import sequences\n",
        "import get_face_areas\n",
        "from get_models import load_weights_EE, load_weights_LSTM\n",
        "import run_functions\n",
        "\n",
        "multimodal_modules_directory = '/content/multimodal_modules'\n",
        "\n",
        "# Check if the expected directory or file exists\n",
        "if not os.path.exists(multimodal_modules_directory):\n",
        "    print(\"Multimodal modules directory does not exist, extracting the ZIP file...\")\n",
        "    # Extract the ZIP file since the directory doesn't exist\n",
        "    # !unzip '/content/notebook_modules.zip' -d /content/\n",
        "    !unzip '/content/drive/MyDrive/Thesis_Data/Multimodal_runs/multimodal_modules.zip' -d /content/\n",
        "else:\n",
        "    print(\"Multimodal modules directory already exists. No need to extract the ZIP file.\")\n",
        "\n",
        "sys.path.append('/content/multimodal_modules')\n",
        "\n",
        "from audio_model import AudioModel\n",
        "from visual_model import VisualModel\n",
        "\n",
        "# Data folders\n",
        "video_data_folder = '/content/VideoMP4_multimodal'\n",
        "audio_data_folder = '/content/AudioWAV_multimodal'\n",
        "\n",
        "# Extract zip folder on Google Drive and save it in Google Colab workspace\n",
        "if not os.path.exists(video_data_folder):\n",
        "    print(\"Video data folder does not exist, extracting the ZIP file...\")\n",
        "    # Extract the ZIP file since the directory doesn't exist\n",
        "    !unzip '/content/drive/MyDrive/Thesis_Data/Multimodal_runs/video_files.zip' -d /content/\n",
        "else:\n",
        "    print(\"Video data folder already exists. No need to extract the ZIP file.\")\n",
        "\n",
        "if not os.path.exists(audio_data_folder):\n",
        "    print(\"Audio data folder does not exist, extracting the ZIP file...\")\n",
        "    # Extract the ZIP file since the directory doesn't exist\n",
        "    !unzip '/content/drive/MyDrive/Thesis_Data/Multimodal_runs/audio_files.zip' -d /content/\n",
        "else:\n",
        "    print(\"Audio data folder already exists. No need to extract the ZIP file.\")\n",
        "\n",
        "def get_dataset(dataset, directory):\n",
        "    # Define the dataset and the directory\n",
        "    if dataset == \"CREMA-D\":\n",
        "        data = pd.read_csv(os.path.join(directory,r\"CREMA-D\\labels_testing.csv\"))\n",
        "        directory = os.path.join(directory,r\"CREMA-D\\audio_testing\")\n",
        "        my_encoding_dict_dataset = {'NEU': 0, 'ANG': 1, 'HAP': 2, 'SAD': 3}\n",
        "\n",
        "    elif dataset == \"CREMA-D-voted\":\n",
        "        data = pd.read_csv(os.path.join(directory,r\"CREMA-D\\labels_v_testing.csv\"))\n",
        "        directory = os.path.join(directory,r\"CREMA-D\\audio_v_testing\")\n",
        "        my_encoding_dict_dataset = {'N': 0, 'A': 1, 'H': 2, 'S': 3}\n",
        "\n",
        "    files = []\n",
        "\n",
        "    # Get a list of all files in the directory (audio files, change for video files)\n",
        "    for file in os.listdir(directory):\n",
        "        if file.endswith('.wav'):\n",
        "            files.append(file)\n",
        "\n",
        "    return files, data, directory, my_encoding_dict_dataset\n",
        "\n",
        "def get_crema_d_dataset(audio_directory, video_directory, labels_file, voted=True):\n",
        "    # Define the dataset and the directory\n",
        "    if voted:\n",
        "        # data = pd.read_csv(os.path.join(directory, labels_file))\n",
        "        # directory = os.path.join(directory,r\"CREMA-D\\audio_testing\")\n",
        "        my_encoding_dict_dataset = {'N': 0, 'A': 1, 'H': 2, 'S': 3}\n",
        "    else:\n",
        "        # data = pd.read_csv(os.path.join(directory,r\"CREMA-D\\labels_v_testing.csv\"))\n",
        "        # directory = os.path.join(directory,r\"CREMA-D\\audio_v_testing\")\n",
        "        my_encoding_dict_dataset = {'NEU': 0, 'ANG': 1, 'HAP': 2, 'SAD': 3}\n",
        "\n",
        "    audio_files = []\n",
        "    video_files = []\n",
        "\n",
        "    # Get a list of all files in the directory (audio files, change for video files)\n",
        "    for file in os.listdir(audio_directory):\n",
        "        if file.endswith('.wav'):\n",
        "            audio_files.append(file)\n",
        "\n",
        "    for file in os.listdir(video_directory):\n",
        "        if file.endswith('.mp4'):\n",
        "            video_files.append(file)\n",
        "\n",
        "    return audio_files, video_files, my_encoding_dict_dataset\n",
        "\n",
        "\n",
        "# Debugging function to check only one file\n",
        "def get_single_file(file):\n",
        "    # Get a single file for debugging\n",
        "    data = pd.read_csv(r\"C:\\Users\\DANIEL\\Desktop\\thesis\\CREMA-D\\labels_testing.csv\")\n",
        "    directory = r\"C:\\Users\\DANIEL\\Desktop\\thesis\\CREMA-D\\audio_testing\"\n",
        "    for row in data.iterrows():\n",
        "        if row[1]['File'] == file:\n",
        "            data = row[1]\n",
        "            break\n",
        "    my_encoding_dict_dataset = {'NEU': 0, 'ANG': 1, 'HAP': 2, 'SAD': 3}\n",
        "    return file, data, directory, my_encoding_dict_dataset\n",
        "\n",
        "def get_label_keys(data, my_encoding_dict_dataset):\n",
        "    # Get the label keys from the dataset\n",
        "    true_labels_multi = data['Emotion'] # Change this to the true labels of the multimodal model\n",
        "    true_labels_audio = data['Emotion'] # Change this to the true labels of the audio model\n",
        "    true_labels_visual = data['Emotion'] # Change this to the true labels of the visual model\n",
        "    label_keys_multi = true_labels_multi.map(my_encoding_dict_dataset).values\n",
        "    label_keys_audio = true_labels_audio.map(my_encoding_dict_dataset).values\n",
        "    label_keys_visual = true_labels_visual.map(my_encoding_dict_dataset).values\n",
        "\n",
        "    return label_keys_multi, true_labels_multi\n",
        "\n",
        "# Separete the audio and the video of the file\n",
        "def separate_audio_video(file):\n",
        "    # Separate the audio and video files\n",
        "\n",
        "    audio_directory = r\"C:\\Users\\DANIEL\\Desktop\\thesis\\CREMA-D\\AudioWav\"\n",
        "    video_directory = r\"C:\\Users\\DANIEL\\Desktop\\thesis\\CREMA-D\\VideoFlash\"\n",
        "\n",
        "    # Lood for audio file in AudioWav folder\n",
        "    audio_files = (os.path.join(audio_directory, file)+'.wav')\n",
        "\n",
        "    # Look for video file in VideoFlash folder\n",
        "    video_files = (os.path.join(video_directory, file)+'.flv')\n",
        "\n",
        "    return audio_files, video_files\n",
        "\n",
        "# Call both models to classify the audio and the video\n",
        "def save_results(results, name):\n",
        "    # Save the results for debugging as a csv file\n",
        "    results_df = pd.DataFrame(results)\n",
        "    # Get current directory\n",
        "    current_dir = os.getcwd()\n",
        "    results_save_path = os.path.join(current_dir, 'multimodal_results')\n",
        "    results_df.to_csv(os.path.join(results_save_path, f'{name}.csv'), index=False)\n",
        "    # results_df.to_csv(f'{name}.csv', index=False)\n",
        "\n",
        "def select_final_label(final_probabilities):\n",
        "    # Select the final label based on the combined probabilities\n",
        "    final_label = np.argmax(final_probabilities)\n",
        "    return final_label\n",
        "\n",
        "def combine_probabilities(audio_prob, video_prob, audio_weight=0.4, video_weight=0.6):\n",
        "    # Implement your logic to combine probabilities from both models\n",
        "    # print()\n",
        "    # print()\n",
        "    # print(\"-----------------Combining Probabilities-----------------\")\n",
        "    # print()\n",
        "    # print(\"Audio Probabilities: \", audio_prob)\n",
        "    audio_weighted = audio_prob*audio_weight\n",
        "    # print(\"Audio Prob. weighted: \", audio_weighted)\n",
        "    # print()\n",
        "    # print(\"Video Probabilities: \", video_prob)\n",
        "    video_weighted = video_prob*video_weight\n",
        "    # print(\"Video Prob. weighted: \", video_weighted)\n",
        "    combined_prob = audio_weighted + video_weighted\n",
        "    # print()\n",
        "    # print(\"Combined Probabilities: \", combined_prob)\n",
        "    return combined_prob\n",
        "\n",
        "def process_audio(audio_file):\n",
        "    audio_classifier = AudioModel()\n",
        "    out_prob, score, index, text_lab = audio_classifier.classify_audio_file(audio_file)\n",
        "    out_prob = out_prob.numpy()\n",
        "    # Add three zeros to match the dimensions of the visual model\n",
        "    out_prob = np.append(out_prob, [0, 0, 0]).reshape(1,7)\n",
        "    return out_prob, score, index, text_lab\n",
        "\n",
        "def process_video(video_file, backbone_model_path, LSTM_model_path):\n",
        "    video_classifier = VisualModel()\n",
        "    out_prob, score, index, text_lab = video_classifier.classify_video_file(video_file, backbone_model_path, LSTM_model_path)\n",
        "    out_prob = reorder_video_probabilities(out_prob)\n",
        "    return out_prob, score, index, text_lab\n",
        "\n",
        "def reorder_video_probabilities(video_probabilities):\n",
        "    # Reorder the video_probabilities to match the audio_probabilities\n",
        "    # Order = ['neu', 'ang', 'hap', 'sad']\n",
        "    # video_model = ['Neutral', 'Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger']\n",
        "    video_model_dict = {'neu' : 0, 'hap' : 1, 'sad' : 2, 'sur' : 3, 'fea' : 4, 'dis' : 5, 'ang' : 6}\n",
        "\n",
        "    new_probabilities = np.array([video_probabilities[video_model_dict['neu']],\n",
        "                                  video_probabilities[video_model_dict['ang']],\n",
        "                                  video_probabilities[video_model_dict['hap']],\n",
        "                                  video_probabilities[video_model_dict['sad']],\n",
        "                                  video_probabilities[video_model_dict['sur']],\n",
        "                                  video_probabilities[video_model_dict['fea']],\n",
        "                                  video_probabilities[video_model_dict['dis']]])\n",
        "\n",
        "    new_probabilities = new_probabilities.reshape(1,7)\n",
        "    # compare old and new probabilities\n",
        "    # print(\"Old Probabilities: \")\n",
        "    # print(video_probabilities)\n",
        "    # print(\"New Probabilities: \")\n",
        "    # print(new_probabilities)\n",
        "    return new_probabilities\n",
        "\n",
        "# Call both models to classify the audio and the video\n",
        "if __name__ == '__main__':\n",
        "    # Test runs are saved in Google Drive in folders named Run_1, Run_2, etc.\n",
        "    # Check the number of the latest run folder\n",
        "    run_folders = [folder for folder in os.listdir('/content/drive/MyDrive/Thesis_Data/Multimodal_runs') if 'Run_' in folder]\n",
        "\n",
        "    continue_from_checkpoint = True\n",
        "    backbone_model_path = '/content/drive/MyDrive/Thesis_Data/CREMA_runs/Pretrained_models/Backbone_models/weights_0_66_37_wo_gl.h5'\n",
        "    LSTM_model_path = '/content/drive/MyDrive/Thesis_Data/CREMA_runs/Pretrained_models/LSTM_models/CREMA-D_with_config.h5'\n",
        "\n",
        "    # If run folders is empty, this is the first run\n",
        "    # Check if run folders is empty\n",
        "    if not run_folders:\n",
        "        this_run = 1\n",
        "        this_run_folder = f'/content/drive/MyDrive/Thesis_Data/Multimodal_runs/Run_{this_run}'\n",
        "        os.makedirs(this_run_folder)\n",
        "        # Create subfolder for checkpoints\n",
        "        checkpoint_folder = os.path.join(this_run_folder, 'checkpoints')\n",
        "        os.makedirs(checkpoint_folder)\n",
        "    elif continue_from_checkpoint:\n",
        "        latest_run = max([int(folder.split('_')[1]) for folder in run_folders])\n",
        "        this_run = latest_run\n",
        "        this_run_folder = f'/content/drive/MyDrive/Thesis_Data/Multimodal_runs/Run_{this_run}'\n",
        "        checkpoint_folder = os.path.join(this_run_folder, 'checkpoints')\n",
        "        checkpoint_files = [csv_file for csv_file in os.listdir(checkpoint_folder)]\n",
        "        last_checkpoint = max([int(checkpoint_file.split(\"_\")[-1].split(\".\")[0]) for checkpoint_file in checkpoint_files])\n",
        "        print(f\"Continuing from checkpoint {last_checkpoint}. (Run {this_run})\")\n",
        "    else:\n",
        "        latest_run = max([int(folder.split('_')[1]) for folder in run_folders])\n",
        "        this_run = latest_run + 1\n",
        "        this_run_folder = f'/content/drive/MyDrive/Thesis_Data/Multimodal_runs/Run_{this_run}'\n",
        "        os.makedirs(this_run_folder)\n",
        "        # Create subfolder for checkpoints\n",
        "        checkpoint_folder = os.path.join(this_run_folder, 'checkpoints')\n",
        "        os.makedirs(checkpoint_folder)\n",
        "\n",
        "    # label_model = ['Neutral', 'Happiness', 'Sadness', 'Surprise', 'Fear', 'Disgust', 'Anger']\n",
        "    # my_encoding_dict_model = {'neu': 0, 'ang': 1, 'hap': 2, 'sad': 3} # Change this to include (or not) the extra classes of the visual model\n",
        "    my_encoding_dict_model = {'neu': 0, 'ang': 1, 'hap': 2, 'sad': 3, 'sur': 4, 'fea': 5, 'dis': 6}\n",
        "    label_names = ['neu', 'ang', 'hap', 'sad'] # Same as above\n",
        "\n",
        "    label_model_decoder = {0: 'Neutral', 1: 'Anger', 2: 'Happiness', 3: 'Sadness', 4: 'Surprise', 5: 'Fear', 6: 'Disgust'}\n",
        "\n",
        "    # dataset = \"CREMA-D\" # Change this to the dataset you are using\n",
        "    # directory = \"path_to_datasets\" # Change this to the directory where you save the datasets\n",
        "    # file = '1001_DFA_ANG_XX' # Change this to the file you want to classify\n",
        "    # file = '1001_IEO_SAD_MD'\n",
        "\n",
        "    # audio_folder = r\"C:\\MyDocs\\DTU\\MSc\\Thesis\\Data\\CREMA-D\\CREMA-D\\AudioWAV\"\n",
        "    # audio_folder = r\"C:\\_HomeDocs\\Ari\\DTU\\00-MSc\\Thesis\\Data\\AudioWAV_testing\"\n",
        "    # video_folder = r\"C:\\MyDocs\\DTU\\MSc\\Thesis\\Data\\CREMA-D\\CREMA-D\\VideoMP4\"\n",
        "    # video_folder = r\"C:\\_HomeDocs\\Ari\\DTU\\00-MSc\\Thesis\\Data\\VideoMP4_testing\"\n",
        "    audio_folder = audio_data_folder\n",
        "    video_folder = video_data_folder\n",
        "\n",
        "    # files, data, directory, my_encoding_dict_dataset = get_dataset(dataset, directory)\n",
        "    labels_data = pd.read_csv(r\"/content/drive/MyDrive/Thesis_Data/Multimodal_runs/voted_combined_labels_corrected_multimodal.csv\")\n",
        "    filenames = labels_data['filename'].tolist()\n",
        "    emotions_list = labels_data['Emotion'].tolist()\n",
        "    labels_list = labels_data['Label'].tolist()\n",
        "    total_data_length = len(filenames)\n",
        "\n",
        "    # predictions_df = labels.copy()\n",
        "    # predictions_df['audio_prob'] = None\n",
        "    # predictions_df['video_prob'] = None\n",
        "\n",
        "    if continue_from_checkpoint:\n",
        "        filenames = filenames[last_checkpoint:]\n",
        "        emotions_list = emotions_list[last_checkpoint:]\n",
        "        labels_list = labels_list[last_checkpoint:]\n",
        "        progress = last_checkpoint + 1\n",
        "    else:\n",
        "        progress = 1\n",
        "\n",
        "    predictions_df = pd.DataFrame(columns=['filename', 'Emotion', 'Label', 'audio_prob', 'video_prob', 'checkpoint'])\n",
        "    predictions_df['filename'] = filenames\n",
        "    predictions_df['Emotion'] = emotions_list\n",
        "    predictions_df['Label'] = labels_list\n",
        "\n",
        "    # files, data, directory, my_encoding_dict_dataset = get_single_file(file)\n",
        "    # label_keys, true_labels = get_label_keys(data, my_encoding_dict_dataset)\n",
        "    # audio_input, video_input = separate_audio_video(file)\n",
        "    # debug_counter = 0\n",
        "    # audio_probs_list = []\n",
        "    # audio_probs_list = []\n",
        "    checkpoint_row = 1\n",
        "    # mp.set_start_method('spawn')\n",
        "    # with mp.Pool(2) as pool:\n",
        "    for file in filenames:\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(f\"Processing file {progress}/{total_data_length}\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        # if debug_counter>=4:\n",
        "            # break\n",
        "        audio_input = os.path.join(audio_folder, file + '.wav')\n",
        "        video_input = os.path.join(video_folder, file + '.mp4')\n",
        "        # audio_input = file\n",
        "        print(f'Audio Input: {audio_input}')\n",
        "        print(f'Video Input: {video_input}')\n",
        "        if file == \"1076_MTI_NEU_XX\":\n",
        "            print(\"Corrupted file. Skipping...\")\n",
        "            progress += 1\n",
        "            checkpoint_row += 1\n",
        "            continue\n",
        "        if file == \"1076_MTI_SAD_XX\":\n",
        "            print(\"Corrupted file. Skipping...\")\n",
        "            progress += 1\n",
        "            checkpoint_row += 1\n",
        "            continue\n",
        "\n",
        "        # audio_result = pool.apply_async(process_audio, (audio_input,))\n",
        "        # video_result = pool.apply_async(process_video, (video_input, backbone_model_path, LSTM_model_path))\n",
        "        audio_result = process_audio(audio_input)\n",
        "        video_result = process_video(video_input, backbone_model_path, LSTM_model_path)\n",
        "\n",
        "        # audio_probabilities, _, _, _ = audio_result.get()\n",
        "        # video_probabilities, _, _, _ = video_result.get()\n",
        "        audio_probabilities = audio_result[0]\n",
        "        video_probabilities = video_result[0]\n",
        "\n",
        "        # Save separate results for debugging\n",
        "        # save_results(audio_probabilities, 'audio_results')\n",
        "        # save_results(video_probabilities, 'video_results')\n",
        "\n",
        "        # print(\"We have now reordered the video probabilities\")\n",
        "        # print(video_probabilities.shape)\n",
        "        # print(video_probabilities)\n",
        "\n",
        "        # Combine results and determine final label\n",
        "        # final_probabilities = combine_probabilities(audio_probabilities, video_probabilities, audio_weight=0.5, video_weight=0.5)\n",
        "        # final_label = select_final_label(final_probabilities)\n",
        "        # final_label_name = label_model_decoder[final_label]\n",
        "\n",
        "        # print(f'Final Label: {final_label}', f'Final Probabilities: {final_probabilities}')\n",
        "        # print(f'Final Label Name: {final_label_name}')\n",
        "        # print(f'True Label: {true_labels}')\n",
        "        # audio_probs_list.append\n",
        "        # video_probs_list\n",
        "        # predictions_df.loc[predictions_df['filename'] == file, 'audio_prob'] = audio_probabilities\n",
        "        # predictions_df.loc[predictions_df['filename'] == file, 'video_prob'] = video_probabilities\n",
        "        predictions_df.at[predictions_df[predictions_df['filename'] == file].index[0], 'audio_prob'] = audio_probabilities\n",
        "        predictions_df.at[predictions_df[predictions_df['filename'] == file].index[0], 'video_prob'] = video_probabilities\n",
        "        predictions_df.at[predictions_df[predictions_df['filename'] == file].index[0], 'checkpoint'] = progress\n",
        "\n",
        "        # debug_counter += 1\n",
        "        if progress % 180 == 0:\n",
        "            # save the DataFrame to a csv file\n",
        "            checkpoint_data = predictions_df.head(checkpoint_row)\n",
        "            checkpoint_data.to_csv(os.path.join(checkpoint_folder,f'run_{this_run}_predicted_checkpoint_{progress}.csv'), index=False)\n",
        "            checkpoint_data.to_pickle(os.path.join(checkpoint_folder,f'run_{this_run}_predicted_checkpoint_{progress}.pkl'))\n",
        "            print(f\"Checkpoint {progress} saved.\")\n",
        "        progress += 1\n",
        "        checkpoint_row += 1\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print(\"------------------------------------------------------------------------------\")\n",
        "    # save the DataFrame to a csv file\n",
        "    predictions_df.to_csv(os.path.join(this_run_folder,f'run_{this_run}_predicted.csv'), index=False)\n",
        "    predictions_df.to_pickle(os.path.join(this_run_folder,f'run_{this_run}_predicted.pkl'))\n",
        "    predictions_df.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}