{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have a DataFrame with columns \"filename\" and \"emotion\"\n",
    "# data = pd.read_csv(\"C:/MyDocs/DTU/MSc/Thesis/Data/MELD/MELD_preprocess_test/pre_process_test.csv\")\n",
    "data = pd.read_csv(\"C:/Users/DANIEL/Desktop/thesis/low-resource-emotion-recognition/MELD_preprocess_test/test_labels.csv\")\n",
    "\n",
    "# directory = \"C:/MyDocs/DTU/MSc/Thesis/Data/MELD/MELD_preprocess_test/MELD_preprocess_test_data\"\n",
    "directory = \"C:/Users/DANIEL/Desktop/thesis/low-resource-emotion-recognition/MELD_preprocess_test/MELD_fine_tune_v1_test_data\"\n",
    "\n",
    "files = []\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.wav'):\n",
    "        files.append(file)\n",
    "\n",
    "# Add filenames to a new column in the DataFrame\n",
    "data['filename'] = files\n",
    "\n",
    "\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "raw_labels = data['Emotion'].values\n",
    "labels = label_encoder.fit_transform(raw_labels)\n",
    "\n",
    "\n",
    "max_length = 16000 * 10  # 10 seconds\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "\n",
    "    # Load audio file\n",
    "    file_to_load = row['filename']\n",
    "    file_to_load_path = os.path.join(directory, file_to_load)\n",
    "    # print()\n",
    "    # print(index)\n",
    "    # print(file_to_load)\n",
    "    # print()\n",
    "\n",
    "    audio, sr = librosa.load(file_to_load_path, sr=16000)\n",
    "\n",
    "    if len(audio) > max_length:\n",
    "        audio = audio[:max_length]\n",
    "    else:\n",
    "        padding = max_length - len(audio)\n",
    "        offset = padding // 2\n",
    "        audio = np.pad(audio, (offset, padding - offset), 'constant')\n",
    "\n",
    "    # Append raw audio data\n",
    "    features.append(audio)\n",
    "\n",
    "    # Encode label\n",
    "    # labels.append(label_encoder.transform([row['Emotion']]))\n",
    "\n",
    "# Convert to arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels).flatten()\n",
    "\n",
    "\n",
    "# Now, `features` and `labels` can be used for training your model\n",
    "# Optionally, save them to disk\n",
    "# np.save('features.npy', features)\n",
    "# np.save('labels.npy', labels)\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# Convert features and labels into PyTorch tensors\n",
    "features_tensor = torch.tensor(features).float()\n",
    "labels_tensor = torch.tensor(labels).long()  # Use .long() for integer labels, .float() for one-hot\n",
    "\n",
    "# Reshape features_tensor to 2D (batch_size, sequence_length)\n",
    "features_tensor = features_tensor.view(features_tensor.shape[0], -1)\n",
    "\n",
    "\n",
    "dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=16)  # Adjust batch size as needed\n",
    "\n",
    "# Initialize the model\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\", num_labels=6)\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load('emotion_recognition_model.pth'))\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "with torch.no_grad():  # Disable gradient calculations\n",
    "    for features, labels in dataloader:\n",
    "        inputs = {'input_values': features, 'labels': labels}\n",
    "        output = model(**inputs)  # Get model outputs for a batch\n",
    "        outputs.append(output)\n",
    "\n",
    "\n",
    "# The outputs are logits, convert them to probabilities using softmax\n",
    "probabilities = [torch.nn.functional.softmax(output.logits, dim=-1) for output in outputs]\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_classes = [torch.argmax(prob, dim=-1) for prob in probabilities]\n",
    "# Convert predicted_classes to a numpy array\n",
    "predicted_classes = torch.cat(predicted_classes).numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (predicted_classes == labels_tensor.numpy()).mean()\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get the label names from the label encoder\n",
    "label_names = label_encoder.classes_\n",
    "\n",
    "\n",
    "# Generate confusion matrix\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(labels_tensor.numpy(), predicted_classes)\n",
    "\n",
    "# Create a DataFrame for the confusion matrix\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix, index=label_names, columns=label_names)\n",
    "\n",
    "# Add a row and column for the total counts\n",
    "confusion_matrix_df['Total'] = confusion_matrix_df.sum(axis=1)\n",
    "confusion_matrix_df.loc['Total'] = confusion_matrix_df.sum()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
